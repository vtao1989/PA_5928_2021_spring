[["index.html", "PA 5928 Data Management &amp; Visualization with R (Spring 2021) Chapter 1 Course Syllabus 1.1 Course description 1.2 Course prerequisites 1.3 Logistics 1.4 Course learning outcomes 1.5 Readings 1.6 Weekly assignment and final project 1.7 Course schedule (Tentative) 1.8 Homework and projects collaboration and submission policy", " PA 5928 Data Management &amp; Visualization with R (Spring 2021) Tao Tao (University of Minnesota) Chapter 1 Course Syllabus 1.1 Course description Introduction to RStudio software. Use of RStudio to carry out R file and related dataset management functions. Tools and techniques for data analysis and statistical programming in quantitative research or related applied areas. Topics include data selection, data manipulation, and data visualization (including charts, plots, histograms, maps, and other graphs). 1.2 Course prerequisites Introductory statistics; ability to create bar graphs, line graphs, and scatter plots in MS Excel; and familiarity with principles of data visualization. 1.3 Logistics Lecture section: 2:30 - 3:45 pm Tuesday and Thursday Instructor: Tao Tao, taotao@umn.edu Instruction mode: Completely online (Link in Canvas) Office hour: 4:00-5:00 pm Tuesday (Link in Canvas) or by appointment Canvas: All course notes will be posted in this course website, but links will be updated on Canvas simultaneously. Canvas will also be used to submit your assignments, final project, and grades. Make sure you have enabled the notification of this course on Canvas. 1.4 Course learning outcomes At the end of this course, students will be able to: Use RStudio to carry out R file and related database management Use R to work with different types of databases and conduct basic data management Use R to visualize data with different types of plots Use R to carry out exploratory data analysis 1.5 Readings The online note is the main study material in this course. The course has several supplementary reading materials, which are available on Canvas. 1. Wickham, H. (2016). ggplot2: elegant graphics for data analysis. Springer. 2. Wickham, H., &amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. OReilly Media, Inc. 1.6 Weekly assignment and final project Weekly assignment includes in-class exercise and after-class assignment. Students are required to submit both of them (R codes) with necessary notes. Weekly assignment is always due on next Monday 11:59 pm. Missing deadline results in a penalty in grades (10% of the total grades for each 24 hours, less than 24 hours will be counted as 24 hours). Check your files before submission. Wrong submission results in a penalty in grades (20% of the total grades). Students will use the knowledge from this course to complete a final project (data analysis for a interested research question and make a poster to show off their work). You can find the description of the final project in the chapter of final project). Grading policy Weekly assignment: 70% Final project: 30% Weekly assignment grading rubric Requirements Grades Codes could generate the results required by the problems 6 Necessary notes to indicate the general idea (usage, function, purpose, or mechanism) 3 Codes and notes are neat and well-organized 1 1.7 Course schedule (Tentative) Week Date Topic Week 1 Tue Mar 9 Course introduction + Introduction to RStudio Week 1 Thu Mar 11 Introduction to R Week 2 Tue Mar 16 Data source introduction Week 2 Thu Mar 18 Data manipulation with base functions Week 3 Tue Mar 23 Data manipulation with dplyr Part I Week 3 Thu Mar 25 Data manipulation with dplyr Part II Week 4 Tue Mar 30 Data visualization with base functions Week 4 Thu Apr 1 Data visualization with ggplot2 Part I Week 5 Spring break Week 6 Tue Apr 13 Data visualization with ggplot2 Part II Week 6 Thu Apr 15 Data visualization with ggplot2 Part III Week 7 Tue Apr 20 Simple statistics in R Part I Week 7 Thu Apr 22 Simple statistics in R Part II Week 8 Tue Apr 27 Exploratory Data Analysis Part I Week 8 Thu Apr 29 Exploratory Data Analysis Part II 1.8 Homework and projects collaboration and submission policy Students can discuss their works with other students, but must code and write up notes by themselves. Plagiarism is not allowed by the university policies. Please do be careful about this. Weekly assignments and projects should be submitted through Canvas. If you cannot attend the class, please write an email to the instructor including a valid reason before the class. When you communicate the instructor with emails, please include PA 5928 at the beginning of your title. "],["introduction-to-rstudio.html", "Chapter 2 Introduction to RStudio 2.1 What is R 2.2 What is RStudio 2.3 Install R + RStudio 2.4 Familiar with the user interface of RStudio 2.5 Create and save R file 2.6 Print Hello, world 2.7 Install and use R Packages 2.8 Make notes 2.9 Tips", " Chapter 2 Introduction to RStudio In this chapter, we will cover some basic operations in RStudio. 2.1 What is R R is a type of programming language and supports many tasks including statistical computation (data cleaning, data management, statistics, machine learning) and graphics (static plots and interactive plots). You can also use it to create website (like this course website), write papers, analyze texts, etc. The most important thing is that R is free and easy to use, thats why it has been applied in many fields. 2.2 What is RStudio RStudio is a programming software for editing and running R code. It has many great features to make R programming easier! 2.3 Install R + RStudio For better coding and running R, you should install both R and RStudio. You could code R with the installation of R only, however, RStudio provides you with more convenience in coding. In this course, we will use RStudio to do all the course lectures and exercises. Please make sure you install both of them! R could be downloaded here and RStudio could be downloaded here (choose the free version). Both Windows OS (Operating System) and Mac OS are supported. You should choose the right one you need for your own system. (If you have any questions about the installation of R or RStudio, please come during the office hours or ask IT for help). 2.4 Familiar with the user interface of RStudio Below is a screenshot of the user interface of RStudio. You will find couple of panes/windows with different usages.(Selvam 2019) Menu/Tool Bar Source The pane where you write and edit your codes. Environment/History Environment lists all the variables that you are currently using. History presents the codes you have run before. Console Console is the original R interactive window. You could run codes and see the results here. Plot/Help Plot window shows the output figures. Help window presents the information of the function or package you are checking. 2.5 Create and save R file Three ways to create an R file in the RStudio: 1. Menu -&gt; File -&gt; New File -&gt; R Script 2. Shortcut: Ctrl + Shift + N 3. Tool Bar -&gt; New file button Also three ways to save R file 1. Menu -&gt; File -&gt; Save 2. Shortcut: Ctrl + S 3. Tool Bar -&gt; Save file button 2.6 Print Hello, world Its time to code something and output the results! Lets print the very classic Hello, world! with print() function. After coding, we could run our codes in several ways: Select the codes or put the cursor in the line of your code, and click the Run button located in the right-top position of the source pane. Select the codes or put the cursor in the line of your code, and use shortcut: Ctrl + Enter You could also click the Re-run button near the Run button to re-run the codes you ran last time. print(&#39;Hello, world!&#39;) ## [1] &quot;Hello, world!&quot; Because what we need to output here is a string variable, we have to put them in the quotation mark. Either single quotation or double quotation mark works well. Lets see another example. print(5928) ## [1] 5928 Here, 5928 is an integer and we do not need to put them in the quotation marks. 2.7 Install and use R Packages R is easy to use because it has tons of packages with different usages. These packages could help you accomplish some complex tasks with just several lines of codes (another reason we like to use R). Some packages have already been installed and you could use them directly, which are base packages. However, most of the packages have to be installed before being called in the codes. There are couple of ways you could install a package. Lets take the tidyverse package for example. 1. Manu -&gt; Tools -&gt; Install Packages... -&gt; Input the package name -&gt; Click Install button 2. Use the code below: install.packages(&quot;gbm&quot;) After the installation of the package, you have import it with library() function before you use the functions in the package. library(gbm) ## Loaded gbm 2.1.8 We will spend more time in future classes to explore the various R packages and their usages. 2.8 Make notes It is important to write notes for your codes. It could help others or even yourself understand your codes easily. Use hash tag to indicate the notes. For example, gbm1 &lt;- gbm(AvgMet~PkAreaH+StpNumH+DisToMin, # formula data=MetM, # dataset var.monotone=c(+1, rep(0,10),rep(0,15)), distribution=&quot;gaussian&quot;, # see the help for other choices n.trees=5000, # number of trees shrinkage=0.001, # shrinkage or learning rate, 0.001 to 0.1 usually work interaction.depth=6, # 1: additive model, 2: two-way interactions, etc. bag.fraction = 0.5, # subsampling fraction, 0.5 is probably best n.minobsinnode = 10, # minimum total weight needed in each node cv.folds = 5) R will not run the codes after hash tags in each line. Please try to write simple but necessary notes for the codes. Keep this as a good habit and you will thank yourself in the future. 2.9 Tips You could divide your codes into sections by putting chunks before each sections with the shortcut Ctrl + Shift + R. This will help you organize your codes. You could run the codes in the chunk by the shortcut Ctrl + Alt + T. Use ? or help() function to find the related instruction or help page, for example, if you want to find the instruction of library() function, just code ?library or help(library) Both will direct you to the instruction page in the help window where you can find how to use these functions. "],["introduction-to-r.html", "Chapter 3 Introduction to R 3.1 Why R and why not R? 3.2 Variable name 3.3 Variable types 3.4 Operations 3.5 Data structures 3.6 Conditional statement (if) 3.7 Loops 3.8 Functions", " Chapter 3 Introduction to R 3.1 Why R and why not R? Before learning R, we need to know why we use R and why we do not use R. Advantages of R (More flexible but less formal) Free and Open source More advanced technique packages Deal with more than one datasets (big data) at the same time Deal with not only data analysis tasks (data visualization, text analysis, creating website, etc.) Advantages of STATA (More formal but less flexible) More algorithms, packages, and implementations of econometrics Faster It is supported by Statacorp so the result is reliable It presents results in a clear format Syntax is simple and standard for most data analysis Help document is formal Besides those advantages, they have a lot of overlaps with each other. People cannot say one is absolutely better than the other. People choose them based on their task requirements. Sometimes, people use both of them for their daily work (e.g., my laptop has both R and STATA). 3.2 Variable name A variable is used to store data including value, vector, data frame, etc., which R could use to manipulate (tutorialspoint 2019b). This chapter introduces variable types, operations between variables, data structures, conditional statements, loops, and functions. Before we start, lets first see how to name a variable. The valid variable name could be constructed with letters, numbers, the dot character (.), and underline character (_). Besides that, a valid variable name should start with a letter or the dot character not followed by a number. Below are some examples of variable names (either good or not good). Examples Validity Discussion var.name  var_name  _var_name  Cannot start with the underline .var_name  var%name  Cannot contain % .2var_name  Cannot use the dot followed by a number to start a variable name 2var_name  Cannot start with a number 3.3 Variable types There are several types of variables which R could recognize, including character, numeric, integer, logical, and complex (Blischak et al. 2019). The type of one variable is decided by the type of value it stores. We can use class() function to check the type of each variable. Character (also known as strings) v &lt;- &quot;Hello, world!&quot; class(v) ## [1] &quot;character&quot; Numeric (real or decimal number/integer) v &lt;- 59.28 class(v) ## [1] &quot;numeric&quot; Integer (L tells R that this number is an integer) v &lt;- 2L class(v) ## [1] &quot;integer&quot; v &lt;-2 class(v) ## [1] &quot;numeric&quot; Logical (Usually True or false) v &lt;- TRUE class(v) ## [1] &quot;logical&quot; v &lt;- FALSE class(v) ## [1] &quot;logical&quot; Complex (complex number is another type of number, different with real number) v &lt;- 1 + 4i class(v) ## [1] &quot;complex&quot; It is important to clearly know the type of the variable since different types of variables may have different functions or operations to deal with. Another caveat is that the outlook of the variable may not show its real variable type. For example, a common situation is listed below. v &lt;- &quot;59.28&quot; class(v) ## [1] &quot;character&quot; Here, the number has quotation marks outside, which means it has been transferred to type character. Therefore, please be careful about variable types! 3.4 Operations An operation tells R the mathematical or logical manipulations among variables (tutorialspoint 2019a). 3.4.1 Assignment operations Assignment operators assign values to variables. Left assignment a &lt;- 1 b &lt;&lt;- &quot;Hello, world!&quot; c = c(1, 3, 4) Right assignment 1 -&gt; a 2 -&gt;&gt; b 3.4.2 Arithmetic operations Add 1 + 1 ## [1] 2 Subtract 5 - 3 ## [1] 2 Multiple 3 * 5 ## [1] 15 Divide 5 - 3 ## [1] 2 Power 5 ^ 2 ## [1] 25 5 ** 2 # you can also do power operation like this ## [1] 25 Mode (find the remainder) 5 %% 2 ## [1] 1 3.4.3 Relational operations The relational operators compare the two elements and return a logical value (TRUE or FALSE). Larger 3 &gt; 4 ## [1] FALSE 5 &gt; 3 ## [1] TRUE Smaller 3 &lt; 5 ## [1] TRUE 4 &lt; 2 ## [1] FALSE Equal 4 == 4 ## [1] TRUE 5 == 4 ## [1] FALSE Note that double equal sign == is relational operation and single equal sign = is assignment operation. No less than (larger or equal to) 3 &gt;= 4 ## [1] FALSE 2 &gt;= 2 ## [1] TRUE No larger than (smaller or equal to) 5 &lt;= 2 ## [1] FALSE 5 &lt;= 5 ## [1] TRUE Not equal 3 != 4 ## [1] TRUE 3 != 3 ## [1] FALSE 3.4.4 Logical operations Logical operators are operations only for logical, numeric, or complex variable types. Most of the time, we apply them on logical values or variables. For numeric variables, 0 is considered FALSE and non-zero numbers are taken as TRUE (DataMentor 2019). You could use T for TRUE or F for FALSE as abbreviation. Logical And TRUE &amp; TRUE ## [1] TRUE FALSE &amp; TRUE ## [1] FALSE FALSE &amp; FALSE ## [1] FALSE Logical Or TRUE | TRUE ## [1] TRUE FALSE | TRUE ## [1] TRUE FALSE | FALSE ## [1] FALSE Logical Not ! TRUE ## [1] FALSE ! FALSE ## [1] TRUE 3.5 Data structures Variables and values could construct different data structures including vector, matrix, data frame, list, and factor (Kabacoff 2019). Vector You could create a vector with c() function. a &lt;- c(5, 9, 2, 8) # create a numeric vector a # show the value of this vector ## [1] 5 9 2 8 b &lt;- c(&#39;hello&#39;, &#39;world&#39;, &#39;!&#39;) # character vector b ## [1] &quot;hello&quot; &quot;world&quot; &quot;!&quot; c &lt;- c(5, &#39;good&#39;) # if you create a vector containing mixed variable types, such as numeric and character, R will restrict them to be the same variable type, here, character c ## [1] &quot;5&quot; &quot;good&quot; You could select elements in the vector by using var_name[#]. Please pay attention on how R indexes its elements in the data structure. a[3] # select the 3rd element ## [1] 2 b[1:3] # select from the 1st to the 3rd element ## [1] &quot;hello&quot; &quot;world&quot; &quot;!&quot; c[2] # select the 2nd element ## [1] &quot;good&quot; 1:3 means from 1 to 3, so it actually stands for three numbers here, which are 1, 2, 3. Matrix You could create a matrix using matrix() function. a &lt;- matrix(1:6, # the data to be put in the matrix, here we use numbers from 1 to 6 nrow = 2, # number of rows in the matrix ncol = 3, # number of columns in the matrix byrow = FALSE) # how to arrange the data in the matrix, FALSE means by columns, TURE means by rows. a ## [,1] [,2] [,3] ## [1,] 1 3 5 ## [2,] 2 4 6 For variable selection, the intuitive way is using coordinates. a[2,3] # select the elements in the 2nd row and 3rd column ## [1] 6 You could also select the entire row or column. a[ ,2] # the 2nd column ## [1] 3 4 a[1, ] # the 1st row ## [1] 1 3 5 Data frame Data frame is a frequently-used data type in R. It could include columns with different types of values stored in them. Lets create a data frame with mixed variables types using data.frame() function. ID &lt;- c(1:4) # create ID Name &lt;- c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;) # create Name Score &lt;- c(69.5, 77.5, 81.5, 90) # create Score df &lt;- data.frame(ID, Name, Score) # combine the variables into one data frame called df df ## ID Name Score ## 1 1 A 69.5 ## 2 2 B 77.5 ## 3 3 C 81.5 ## 4 4 D 90.0 We created a data frame storing the students ID, name, and their test scores. We can select elements from this data frame with couple of ways. df[2,3] # 2nd row and 3rd column ## [1] 77.5 df[&#39;ID&#39;] # column of variable ID ## ID ## 1 1 ## 2 2 ## 3 3 ## 4 4 df[c(&#39;ID&#39;, &#39;Score&#39;)] # column of ID and Score ## ID Score ## 1 1 69.5 ## 2 2 77.5 ## 3 3 81.5 ## 4 4 90.0 There is another way to select the column by its name, which is more frequently used. When you type $ after the name of the data frame, RStudio will list all the variables in that data frame. df$Name # column of variable Name ## [1] A B C D ## Levels: A B C D List A list could store mixed types of values, which is different from vector. a &lt;- list(ID = c(1, 2), Name = c(&#39;A&#39;, &#39;B&#39;), Score = c(69.5, 89)) When you want to select elements from a list, you could do it in a similar way as a vector. However, list does not define row or column, so you cannot use 2-D coordinates to select elements like a data frame. a[1] ## $ID ## [1] 1 2 a[2:3] ## $Name ## [1] &quot;A&quot; &quot;B&quot; ## ## $Score ## [1] 69.5 89.0 Someone might be confusing since list looks similar to data frame. Here is a good discussion about it. Due to the time limitation, we will not cover this discussion in class. The main idea is that list is more flexible than data frame, while data frame has more restrictions. However, since data frame is more similar to 2-D table structure which is more frequently used in our daily work, we use data frame more than list. Factor Factor is the nominal variable in R. This type will be very useful when we want to analyze data from different groups, such as gender, school, etc. a &lt;- c(1, 2, 1, 2, 3, 3, 1, 1) class(a) ## [1] &quot;numeric&quot; afactor &lt;- factor(a) class(afactor) ## [1] &quot;factor&quot; Use levels() to check the categories in variable afactor. levels(afactor) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; 3.6 Conditional statement (if) if (test_expression){ statement_1 } else { statement_2 } If the test_expression returns TRUE, then the codes will go to statement_1, if it returns FALSE, the codes will go to statement_2. You could also omit the else part. if (test_expression){ statement_1 } If the test_expression returns FALSE, the codes will continue to next line. x &lt;- 5 if (x &gt; 3){ print(&#39;x is larger than 3&#39;) } else { print(&#39;x is not larger than 3&#39;) } ## [1] &quot;x is larger than 3&quot; x &lt;- 1 if (x &gt; 3){ print(&#39;x is larger than 3&#39;) } Some other conditional statements include switch() and which(). 3.7 Loops Loops help us repeat the codes. for loop is a commonly-used one. for (range){ statement } range will provide the range for a variable. The form could be i in 1:3, which shows that i will be 1, 2, and 3 in each loop. for (i in 1:3){ print(i) } ## [1] 1 ## [1] 2 ## [1] 3 You can nest conditional statement and loop together like the codes below (print the numbers (from 5 to 10) that are smaller than 7). Use the whole loop part to replace the statement in conditional statement. for (i in 5:10) { if(i &lt; 7) { print(i) } } ## [1] 5 ## [1] 6 3.8 Functions Functions are codes that have been defined with specific usage. You only need to input some necessary variables and functions will do the tasks. To use function, you start with the name of the function followed with a pair of parentheses. Then, you input some arguments in the parentheses to give instructions to the function. For example, sum() function could help you add the all the numbers together in a vector or data frame and return the result. sum(c(1, 4, 10, 5)) ## [1] 20 Another example is mean() function, which could help you average the numbers in a vector or data frame and return the result. mean(c(1, 4, 10, 5)) ## [1] 5 In functions, some arguments must be input. For example, you need to input the dataset in mean() function. However, some arguments are not necessary to be input because they have default values. If you do not specify these arguments, then, the function will use their default values. For example, after checking the help page of mean(), you will find that there is an other argument called na.rm which decides whether the missing values should be removed. Lets see the example below. data &lt;- c(1, 4, 5, NA) mean(data) ## [1] NA To avoid this, we need to add an argument to reset the value of na.rm in the mean() function. mean(data, na.rm = TRUE) ## [1] 3.333333 na.rm tells the function whether missing values should be removed during the calculation. Its default value is FALSE, which means that the missing values should not be removed. Calculating the average of a list of numbers containing missing value will return a missing value. Thats why we get NA from our first try. In our second try, we set the value of na.rm to TRUE. The function removes the missing values and we have the correct result in our second try. It is important to use the right function to do the right task. To do this, you have to be familiar with the functions you are using. It needs more practice. "],["data-manipulation-with-base-functions.html", "Chapter 4 Data Manipulation with Base Functions 4.1 Import and save datasets 4.2 View data 4.3 Data selection 4.4 Conditional selection 4.5 Deal with missing values 4.6 Subset 4.7 Merge two datasets 4.8 Column operation", " Chapter 4 Data Manipulation with Base Functions We will introduce how to manipulate with different datasets using base functions in R. 4.1 Import and save datasets There couple of ways to importing and saving different types of datasets (Quick-R 2019c, 2019a). 4.1.1 Import data from commonly-used file types CSV file mydata &lt;- read.csv(&#39;c:/minneapolis.csv&#39;, ## file location and name header = TRUE, ## read the first sep = &#39;,&#39;) ## which type of separation EXCEL file library(readxl) dataset &lt;- read_excel(&#39;c:/mydata.xlsx&#39;, # file location and name sheet = &#39;data&#39;) # name or index of the sheet dta STATA file library(foreign) mydata &lt;- read.dta(&#39;c:/mydata.dta&#39;) # file location and name Below is an easy way to load datasets in RStudio. System tool Besides importing data by codes, you could also import data with the system tool. If this is your first time to use this tool, there may be a process to install the packages depending your options. But dont worry, RStudio can do it by itself. You just need to click the button to approve the installation. File -&gt; Import dataset -&gt; choose the type of dataset you want to import There are some other options you could set in the import functions listed above (e.g., specify a variable type or try to skip some of the rows). 4.1.2 Save file CSV file write.csv(df, # data &#39;c:/filename.csv&#39;) # file location and name EXCEL file library(xlsx) write.xlsx(mydata, # data &quot;c:/mydata.xlsx&quot;) # file location and name dta STATA file library(foreign) write.dta(mydata, &quot;c:/mydata.dta&quot;) Usually, it takes less time to save file in CSV and CSV file has a smaller size in storage. Note that if you do not specify file location when saving it, R will save it to the working folder. 4.1.3 File location As you can see in the examples, you need to specify the location (or path) of the file to make sure that R could find your file in the right position. Usually you could find the location by checking the system property of the file. In window system, you need to use forward slash / to separate the locations. However, in Mac system, you use back slash \\. Inputting file location could be tedious, but you could avoid this. Here is how. First, put your R file and dataset in the same folder. Then start the R file by double clicking it. R will use the folder where the R file locates as the working folder. In this way, you can only specify the name of the dataset when importing it. This is highly recommended. It would be easier for others to check your codes as they do not need to change the path of the file. 4.2 View data You could view the variable names and simple description in the Environment pane on the right-top position of RStudio. If you want to view more information, click the variable name and view the variable in a new window. Here, we use the Minneapolis one-year ACS data as a example. This dataset contains the demographic information of the respondents in the city of Minneapolis in the ACS survey from 2010 to 2019. The table below lists the variable names and their descriptions. Variable Name Description YEAR Year The year when the data was collected. SEX Gender Gender of the respondent. 1 = Male 2 = Female AGE Age Age of the respondent (0 indicates age is smaller than 1). RACE Race Race of the respondent. 1 = White 2 = Black/African American/Negro 3 = Other HISPAN Hispanic origin Hispanic origin of the respondent. 0 = Not Hispanic 1 = Mexican 2 = Puerto Rican 3 = Cuban 4 = Other EDUC Educational attainment Respondents educational attainment, as measured by the highest year of school or degree completed. 0 = N/A or no schooling 1 = Nursery school to grade 4 2 = Grade 5, 6, 7, or 8 3 = Grade 9 4 = Grade 10 5 = Grade 11 6 = Grade 12 7 = 1 year of college 8 = 2 years of college 9 = 3 years of college 10 = 4 years of college 11 = 5+ years of college EMPSTAT Employment status Whether the respondent was a part of the labor force  working or seekingwork  and, if so, whether the person was currently unemployed. 0 = N/A 1 = Employed 2 = Unemployed 3 = Not in labor force INCTOT Total personal income Each respondents total pre-tax personal income or losses from all sources for the previous year FTOTINC Total family income The total pre-tax money income earned by ones family from all sources for the previous year. minneapolis &lt;- read.csv(&#39;minneapolis.csv&#39;) You could also view the data in the new window by View() function. Please pay attention that it is initial-capitalized. View(minneapolis) View the first ten observations (rows) in the dataset. stands for double class, which is a sub-type of numerical variable type. head(minneapolis, n = 10) ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 1 2010 2 59 1 0 10 1 33100 49100 ## 2 2010 2 29 1 0 10 1 16000 49100 ## 3 2010 1 54 2 0 7 3 1100 NA ## 4 2010 2 47 2 0 5 2 4800 4800 ## 5 2010 1 59 2 0 10 2 0 4800 ## 6 2010 2 10 2 0 1 0 NA 4800 ## 7 2010 1 24 1 0 5 1 15000 15000 ## 8 2010 1 26 2 3 6 1 18000 18000 ## 9 2010 1 51 1 0 6 1 35200 74400 ## 10 2010 2 47 1 0 6 1 39200 74400 view the last five observations in the dataset. tail(minneapolis, n = 5) ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 25531 2019 2 66 1 0 7 1 77000 77000 ## 25532 2019 2 29 3 1 6 3 0 38000 ## 25533 2019 1 28 3 1 0 1 38000 38000 ## 25534 2019 1 6 3 1 1 0 NA 38000 ## 25535 2019 1 1 3 1 0 0 NA 38000 List the names of variables in the dataset (Quick-R 2019b). names(minneapolis) ## [1] &quot;YEAR&quot; &quot;SEX&quot; &quot;AGE&quot; &quot;RACE&quot; &quot;HISPAN&quot; &quot;EDUC&quot; &quot;EMPSTAT&quot; ## [8] &quot;INCTOT&quot; &quot;FTOTINC&quot; colnames(minneapolis) ## [1] &quot;YEAR&quot; &quot;SEX&quot; &quot;AGE&quot; &quot;RACE&quot; &quot;HISPAN&quot; &quot;EDUC&quot; &quot;EMPSTAT&quot; ## [8] &quot;INCTOT&quot; &quot;FTOTINC&quot; List the structure of the dataset. str(minneapolis) ## &#39;data.frame&#39;: 25535 obs. of 9 variables: ## $ YEAR : int 2010 2010 2010 2010 2010 2010 2010 2010 2010 2010 ... ## $ SEX : int 2 2 1 2 1 2 1 1 1 2 ... ## $ AGE : int 59 29 54 47 59 10 24 26 51 47 ... ## $ RACE : int 1 1 2 2 2 2 1 2 1 1 ... ## $ HISPAN : int 0 0 0 0 0 0 0 3 0 0 ... ## $ EDUC : int 10 10 7 5 10 1 5 6 6 6 ... ## $ EMPSTAT: int 1 1 3 2 2 0 1 1 1 1 ... ## $ INCTOT : num 33100 16000 1100 4800 0 NA 15000 18000 35200 39200 ... ## $ FTOTINC: num 49100 49100 NA 4800 4800 4800 15000 18000 74400 74400 ... List the dimensions of the dataset dim(minneapolis) ## [1] 25535 9 List the number of rows in the dataset nrow(minneapolis) ## [1] 25535 List the number of columns in the dataset. ncol(minneapolis) ## [1] 9 4.3 Data selection Select one column with 5 rows of observations. head(minneapolis$YEAR, n = 5) # by name ## [1] 2010 2010 2010 2010 2010 head(minneapolis[1], n = 5) # by index ## YEAR ## 1 2010 ## 2 2010 ## 3 2010 ## 4 2010 ## 5 2010 Select several columns with 5 rows of observations. head(minneapolis[c(&#39;YEAR&#39;, &#39;SEX&#39;)], n = 5) # by name ## YEAR SEX ## 1 2010 2 ## 2 2010 2 ## 3 2010 1 ## 4 2010 2 ## 5 2010 1 head(minneapolis[c(1, 3, 5)], n = 5) # by index ## YEAR AGE HISPAN ## 1 2010 59 0 ## 2 2010 29 0 ## 3 2010 54 0 ## 4 2010 47 0 ## 5 2010 59 0 Select one row by index minneapolis[2,] # by index number ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 2 2010 2 29 1 0 10 1 16000 49100 Select several rows minneapolis[2:3, ] # by index ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 2 2010 2 29 1 0 10 1 16000 49100 ## 3 2010 1 54 2 0 7 3 1100 NA minneapolis[c(1,5,9), ] # by index ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 1 2010 2 59 1 0 10 1 33100 49100 ## 5 2010 1 59 2 0 10 2 0 4800 ## 9 2010 1 51 1 0 6 1 35200 74400 4.4 Conditional selection newdata &lt;- minneapolis[minneapolis$YEAR == 2010, ] head(newdata) ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 1 2010 2 59 1 0 10 1 33100 49100 ## 2 2010 2 29 1 0 10 1 16000 49100 ## 3 2010 1 54 2 0 7 3 1100 NA ## 4 2010 2 47 2 0 5 2 4800 4800 ## 5 2010 1 59 2 0 10 2 0 4800 ## 6 2010 2 10 2 0 1 0 NA 4800 newdata &lt;- minneapolis[(minneapolis$YEAR == 2010) &amp; (minneapolis$EDUC &lt; 5), ] head(newdata) ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 6 2010 2 10 2 0 1 0 NA 4800 ## 11 2010 2 8 1 0 1 0 NA 74400 ## 41 2010 1 16 2 0 4 3 0 7900 ## 42 2010 2 85 1 0 2 3 12000 NA ## 47 2010 1 10 3 0 1 0 NA NA ## 55 2010 1 5 1 0 1 0 NA 132000 newdata &lt;- minneapolis$INCTOT[minneapolis$YEAR == 2010] head(newdata) ## [1] 33100 16000 1100 4800 0 NA 4.5 Deal with missing values In R, the missing values is presented as NA. Test the existence of missing values with is.na() function. We use an revised old example here. ID &lt;- c(1:4) # create variable ID Name &lt;- c(&#39;A&#39;, NA, &#39;C&#39;, &#39;D&#39;) # create variable Name Score &lt;- c(69.5, 77.5, NA, 90) # create variable Score df &lt;- data.frame(ID, Name, Score) # combine the varibles into one data frame called df is.na(df) ## ID Name Score ## [1,] FALSE FALSE FALSE ## [2,] FALSE TRUE FALSE ## [3,] FALSE FALSE TRUE ## [4,] FALSE FALSE FALSE Assign missing values df$Score[df$Score == 90] &lt;- NA df ## ID Name Score ## 1 1 A 69.5 ## 2 2 &lt;NA&gt; 77.5 ## 3 3 C NA ## 4 4 D NA NAs will influence some functions. mean(df$Score) # get the mean value (does not ignore NA) ## [1] NA mean(df$Score, na.rm=TRUE) # (ignore NA) ## [1] 73.5 Test if the observations in the dataset has NAs. complete.cases(df) ## [1] TRUE FALSE FALSE FALSE Find the observations with no NAs. na.omit(df) ## ID Name Score ## 1 1 A 69.5 4.6 Subset subset() is another way to select the data you want. Select observations in the Minneapolis population dataset when YEAR is equal to 2010. newdata &lt;- subset(minneapolis, YEAR == 2010) head(newdata) ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 1 2010 2 59 1 0 10 1 33100 49100 ## 2 2010 2 29 1 0 10 1 16000 49100 ## 3 2010 1 54 2 0 7 3 1100 NA ## 4 2010 2 47 2 0 5 2 4800 4800 ## 5 2010 1 59 2 0 10 2 0 4800 ## 6 2010 2 10 2 0 1 0 NA 4800 Select two columns from the dataset. newdata &lt;- subset(minneapolis, select = c(&#39;YEAR&#39;, &#39;AGE&#39;)) head(newdata, n = 5) ## YEAR AGE ## 1 2010 59 ## 2 2010 29 ## 3 2010 54 ## 4 2010 47 ## 5 2010 59 4.7 Merge two datasets merge() function does the same work as vlookup() in excel and Join function in ArcGIS. It links two datasets based on their common variable (the variable they both have). ID &lt;- c(1:4) # create variable ID Name &lt;- c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;) # create variable Name Score1 &lt;- c(69.5, 77.5, 99, 90) # create variable Score1 df1 &lt;- data.frame(ID, Name, Score1) # combine the variables into one data frame called df1 df1 ## ID Name Score1 ## 1 1 A 69.5 ## 2 2 B 77.5 ## 3 3 C 99.0 ## 4 4 D 90.0 Name &lt;- c(&#39;A&#39;, &#39;D&#39;, &#39;C&#39;) # create variable Name Score2 &lt;- c(98, 46, 55) # create variable Score2 df2 &lt;- data.frame(Name, Score2) # combine the variables into one data frame called df2 df2 ## Name Score2 ## 1 A 98 ## 2 D 46 ## 3 C 55 merge(df1, df2, # data frames need to be merged by = &#39;Name&#39;, # name of the column/variable used for merging all.x = TRUE) # keep all observations in the first data frame after merging ## Name ID Score1 Score2 ## 1 A 1 69.5 98 ## 2 B 2 77.5 NA ## 3 C 3 99.0 55 ## 4 D 4 90.0 46 merge(df1, df2, by = &#39;Name&#39;, all.y = TRUE) # keep all observations in the first dataframe after merging ## Name ID Score1 Score2 ## 1 A 1 69.5 98 ## 2 C 3 99.0 55 ## 3 D 4 90.0 46 You could keep all the observations in both two data frames by set all = TRUE in the function. We will cover more about this in our lecture about dplyr. 4.8 Column operation Column operation or vector operation is a very important idea in R. It applies the operations in two columns or the function in one column directly rather than applies them on each element one by one. ID &lt;- c(1:4) # create variable ID Name &lt;- c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;) # create variable Name Score1 &lt;- c(69.5, 77.5, 99, 90) # create variable Score1 Score2 &lt;- c(98, 46, 55, 70) # create variable Score2 df &lt;- data.frame(ID, Name, Score1, Score2) # combine the varibles into one data frame called df df ## ID Name Score1 Score2 ## 1 1 A 69.5 98 ## 2 2 B 77.5 46 ## 3 3 C 99.0 55 ## 4 4 D 90.0 70 Create a new column in the data frame to calculate the sum of score 1 and score 2 df$totalsocre &lt;- df$Score1 + df$Score2 df ## ID Name Score1 Score2 totalsocre ## 1 1 A 69.5 98 167.5 ## 2 2 B 77.5 46 123.5 ## 3 3 C 99.0 55 154.0 ## 4 4 D 90.0 70 160.0 Create a new column in the data frame to calculate the mean of score 1 and score 2 df$meansocre &lt;- (df$Score1 + df$Score2)/2 df ## ID Name Score1 Score2 totalsocre meansocre ## 1 1 A 69.5 98 167.5 83.75 ## 2 2 B 77.5 46 123.5 61.75 ## 3 3 C 99.0 55 154.0 77.00 ## 4 4 D 90.0 70 160.0 80.00 "],["data-manipulation-with-dplyr.html", "Chapter 5 Data Manipulation with dplyr 5.1 select() 5.2 filter() 5.3 arrange() 5.4 mutate() 5.5 group_by() and summarise() 5.6 join() 5.7 pivot_wider() and pivot_longer() in tidyr", " Chapter 5 Data Manipulation with dplyr In this chapter, we will learn a very popular package dplyr to deal with data manipulation. We will mainly go through its main functions (BiomedicalDataScience 2019; r-project 2019). 5.1 select() Before the lecture, install the package in your computer. install.packages(&#39;dplyr&#39;) ## you only need to install this package once Lets first import this package. Also, we import the Minneapolis ACS dataset. library(dplyr) minneapolis &lt;- read.csv(&#39;minneapolis.csv&#39;) If we want to select one or more columns (i.e., variables) from the dataset. We could use select() in dplyr. It is similar to subset() , but here, you do not need to use select = c('mpg', 'disp'). You use the names of the columns directly in the function. df &lt;- select(minneapolis, # name of the data frame YEAR, SEX, AGE) # column/variable names you want to select head(df, 3) ## YEAR SEX AGE ## 1 2010 2 59 ## 2 2010 2 29 ## 3 2010 1 54 You could also use the index of the columns. df &lt;- select(minneapolis, # name of the data frame c(1:3)) # index of the columns/variables you want to select head(df, 3) ## YEAR SEX AGE ## 1 2010 2 59 ## 2 2010 2 29 ## 3 2010 1 54 pipe The codes above is kind of a traditional way to do the work. We start with a function and put parameters in the function. However, this is not the typical way to use dplyr. The codes below is a more dplyr way people use the package. We start with the name of the data frame. Then, we put a special sign %&gt;% called pipe after it. We continue from a new line and write the function we want to use. Besides that, we could add more functions with the pipe operator. For example, only show first three observations with head(). minneapolis %&gt;% # name of the data frame select(YEAR, SEX, AGE) %&gt;% # select the columns by their names head(3) ## YEAR SEX AGE ## 1 2010 2 59 ## 2 2010 2 29 ## 3 2010 1 54 The original codes include more (see below). When comparing the codes above and below, you will find that original codes use . as the input of the data frame in the function. However, for easy coding, this . could be omitted if it is in the starting position among the input parameters in the functions. In other words, if this . is not in the starting position, it cannot be omitted. minneapolis %&gt;% select(., YEAR, SEX, AGE) %&gt;% head(., 3) ## YEAR SEX AGE ## 1 2010 2 59 ## 2 2010 2 29 ## 3 2010 1 54 You can also write the codes in only one line, just like the codes below. However, it is recommended to write codes with one function in one line to improve the readiness of the codes. minneapolis %&gt;% select(YEAR, SEX, AGE) %&gt;% head(3) ## YEAR SEX AGE ## 1 2010 2 59 ## 2 2010 2 29 ## 3 2010 1 54 The pipe operation is named after the art work, This is not a pipe, from René Magritte. We will keep using the fashion of pipe in the following lectures. In addition, you can use Ctrl + Shift + M in RStudio to quickly input the pipe operator. Besides selecting some columns you want, you could also exclude the columns you do not want by putting a negative sign - before the variable. minneapolis %&gt;% select(-HISPAN, - FTOTINC) %&gt;% ## exclude HISPAN and FTOTINC from the data frame head(3) ## YEAR SEX AGE RACE EDUC EMPSTAT INCTOT ## 1 2010 2 59 1 10 1 33100 ## 2 2010 2 29 1 10 1 16000 ## 3 2010 1 54 2 7 3 1100 You could use : to select a range of variables. minneapolis %&gt;% select(YEAR:RACE) %&gt;% # select from YEAR to RACE in the data frame head(3) ## YEAR SEX AGE RACE ## 1 2010 2 59 1 ## 2 2010 2 29 1 ## 3 2010 1 54 2 Or exclude a range of variables. minneapolis %&gt;% select(-(YEAR:RACE)) %&gt;% # exclude the variables from YEAR to RACE in the data frame head(3) ## HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 1 0 10 1 33100 49100 ## 2 0 10 1 16000 49100 ## 3 0 7 3 1100 NA Below are some advanced techniques to select columns. You can select the column with their names starting with the string(s) you specify in starts_with(). For example, the codes below select the columns with names starting with E. minneapolis %&gt;% select(starts_with(&#39;E&#39;)) %&gt;% head(3) ## EDUC EMPSTAT ## 1 10 1 ## 2 10 1 ## 3 7 3 It may not make sense to you at first. I apologize that the example above is not a good one. In my experience, I have dealt with a traffic dataset that contains variables such as AADT_2010, AADT_2011, AADT_2012, AADT_2013, AADT_2014, AADT_2015. In this case, you can use codes like select(starts_with('AADT')) to select all similar columns. Since we have starts_with(), you may be wondering it there is ends_with(). The answer is yes. minneapolis %&gt;% select(ends_with(&#39;E&#39;)) %&gt;% head(3) ## AGE RACE ## 1 59 1 ## 2 29 1 ## 3 54 2 You can use contains() to select the columns containing the string(s) you specify. minneapolis %&gt;% select(contains(&#39;INC&#39;)) %&gt;% head(3) ## INCTOT FTOTINC ## 1 33100 49100 ## 2 16000 49100 ## 3 1100 NA Other similar functions include num_range(), matches(), one_of(), etc. Feel free to check how they can be used with help(). 5.2 filter() In dplyr, we use filter() to select the rows satisfying some conditions. minneapolis %&gt;% filter(YEAR == 2015) %&gt;% head(3) ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 1 2015 2 37 3 0 11 1 125000 125000 ## 2 2015 1 18 1 0 6 3 2500 NA ## 3 2015 1 91 1 0 6 3 8400 NA Add more conditions by using , to separate them. minneapolis %&gt;% filter(YEAR == 2015, AGE == 37, SEX == 1) %&gt;% head(3) ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 1 2015 1 37 1 0 7 1 55000 75000 ## 2 2015 1 37 1 0 6 1 40000 73600 ## 3 2015 1 37 1 0 7 1 80000 80000 minneapolis %&gt;% filter(YEAR == 2015, INCTOT &gt; mean(INCTOT, na.rm = T)) %&gt;% ## select those with an above-average personal income head(3) ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 1 2015 2 37 3 0 11 1 125000 125000 ## 2 2015 2 42 1 0 11 1 160200 270400 ## 3 2015 1 42 1 0 10 1 110200 270400 , serves as an logical and here. Instead, you can use &amp;. minneapolis %&gt;% filter(YEAR == 2015 &amp; INCTOT &gt; mean(INCTOT, na.rm = T)) %&gt;% head(3) ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 1 2015 2 37 3 0 11 1 125000 125000 ## 2 2015 2 42 1 0 11 1 160200 270400 ## 3 2015 1 42 1 0 10 1 110200 270400 You may use | to stand for logical or. minneapolis %&gt;% filter(YEAR == 2015 | YEAR == 2017) %&gt;% ## select those in 2015 or 2017 head() ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 1 2015 2 37 3 0 11 1 125000 125000 ## 2 2015 1 18 1 0 6 3 2500 NA ## 3 2015 1 91 1 0 6 3 8400 NA ## 4 2015 2 18 1 0 6 1 1000 NA ## 5 2015 1 19 1 0 6 3 3000 NA ## 6 2015 2 18 1 0 6 1 3300 NA 5.3 arrange() We could arrange the order of some columns by arrange() functions. minneapolis %&gt;% arrange(YEAR) %&gt;% # arrange YEAR in ascending order head(5) ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 1 2010 2 59 1 0 10 1 33100 49100 ## 2 2010 2 29 1 0 10 1 16000 49100 ## 3 2010 1 54 2 0 7 3 1100 NA ## 4 2010 2 47 2 0 5 2 4800 4800 ## 5 2010 1 59 2 0 10 2 0 4800 Or maybe we want YEAR to be in a descending order. Just put a desc() outside the variable. minneapolis %&gt;% arrange(desc(YEAR)) %&gt;% head(5) ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 1 2019 1 20 1 0 7 2 4600 NA ## 2 2019 1 58 1 0 6 1 2500 NA ## 3 2019 1 20 1 0 7 1 8000 NA ## 4 2019 1 15 2 0 2 0 9300 NA ## 5 2019 1 6 1 0 1 0 NA NA We could put them together by using pipe operators to connect them. minneapolis %&gt;% filter(YEAR == 2010) %&gt;% ## filter rows select(YEAR, SEX, AGE) %&gt;% ## select columns arrange(desc(SEX), AGE) %&gt;% ## arrange order head(5) ## show the first 5 observations ## YEAR SEX AGE ## 1 2010 2 0 ## 2 2010 2 0 ## 3 2010 2 0 ## 4 2010 2 0 ## 5 2010 2 0 5.4 mutate() We use mutate() to do operation among the variables and create a new column to store them. minneapolis %&gt;% select(INCTOT) %&gt;% mutate(INCTOTK = INCTOT/1000) %&gt;% ## transfer the unit of personal income from dollar to k dollar head(5) ## INCTOT INCTOTK ## 1 33100 33.1 ## 2 16000 16.0 ## 3 1100 1.1 ## 4 4800 4.8 ## 5 0 0.0 You can include more than one assignment operations in mutate(). minneapolis %&gt;% select(INCTOT, FTOTINC) %&gt;% mutate(INCTOTK = INCTOT/1000, FTOTINCK = FTOTINC/1000) %&gt;% head(10) ## INCTOT FTOTINC INCTOTK FTOTINCK ## 1 33100 49100 33.1 49.1 ## 2 16000 49100 16.0 49.1 ## 3 1100 NA 1.1 NA ## 4 4800 4800 4.8 4.8 ## 5 0 4800 0.0 4.8 ## 6 NA 4800 NA 4.8 ## 7 15000 15000 15.0 15.0 ## 8 18000 18000 18.0 18.0 ## 9 35200 74400 35.2 74.4 ## 10 39200 74400 39.2 74.4 You can use ifelse() to change the value satisfying the specified condition. if_else() works but is more strict in variable types. See its help page for more information. minneapolis %&gt;% mutate( SEX = ifelse(SEX == 1, &#39;Male&#39;, &#39;Female&#39;) ## change the value of SEX from 1 to Male, otherwise, Female ) %&gt;% head(5) ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 1 2010 Female 59 1 0 10 1 33100 49100 ## 2 2010 Female 29 1 0 10 1 16000 49100 ## 3 2010 Male 54 2 0 7 3 1100 NA ## 4 2010 Female 47 2 0 5 2 4800 4800 ## 5 2010 Male 59 2 0 10 2 0 4800 If you have more than one conditions, you can use case_when(). minneapolis %&gt;% mutate( RACE = case_when( ## change RACE from numeric values to racial categories RACE == 1 ~ &#39;White&#39;, RACE == 2 ~ &#39;African American&#39;, RACE == 3 ~ &#39;Other&#39; ) ) %&gt;% head(5) ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC ## 1 2010 2 59 White 0 10 1 33100 49100 ## 2 2010 2 29 White 0 10 1 16000 49100 ## 3 2010 1 54 African American 0 7 3 1100 NA ## 4 2010 2 47 African American 0 5 2 4800 4800 ## 5 2010 1 59 African American 0 10 2 0 4800 minneapolis %&gt;% mutate( IncLevl = case_when( ## categorize personal income into three levels INCTOT &lt; median(INCTOT, na.rm = T) ~ &#39;Low income&#39;, INCTOT &gt; median(INCTOT, na.rm = T) ~ &#39;High income&#39;, TRUE ~ &#39;Median income&#39; ) ) %&gt;% head(5) ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC IncLevl ## 1 2010 2 59 1 0 10 1 33100 49100 High income ## 2 2010 2 29 1 0 10 1 16000 49100 Low income ## 3 2010 1 54 2 0 7 3 1100 NA Low income ## 4 2010 2 47 2 0 5 2 4800 4800 Low income ## 5 2010 1 59 2 0 10 2 0 4800 Low income 5.5 group_by() and summarise() We use group_by() to do aggregation (group the observations based the values of one or one more columns) work and summarise() to calculate some statistics related to each group. Below is a plot to show how it works. dataset %&gt;% group_by(Name) %&gt;% summarise(TotalSocre = sum(Score)) When it comes to our Minneapolis ACS dataset, we can use the combination of group_by() and summarise() to help use with many tasks. minneapolis %&gt;% group_by(YEAR) %&gt;% ## aggregate the data based on YEAR summarise(count = n(), ## number of respondents in each year AvgInc = mean(INCTOT, na.rm = T)) ## average personal income in each year ## # A tibble: 10 x 3 ## YEAR count AvgInc ## * &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2010 2131 37605. ## 2 2011 2431 36715. ## 3 2012 2517 33152. ## 4 2013 2549 37392. ## 5 2014 2545 37238. ## 6 2015 2524 40902. ## 7 2016 2744 42901. ## 8 2017 2857 46994. ## 9 2018 2673 45557. ## 10 2019 2564 48519. minneapolis %&gt;% mutate( RACE = case_when( ## change RACE from numeric values to racial categories RACE == 1 ~ &#39;White&#39;, RACE == 2 ~ &#39;African American&#39;, RACE == 3 ~ &#39;Other&#39; ) ) %&gt;% group_by(YEAR, RACE) %&gt;% ## aggregate the data based on YEAR and RACE summarise(MaxInc = max(INCTOT, na.rm = T)) ## maximum personal income for different racial groups in each year ## # A tibble: 30 x 3 ## # Groups: YEAR [10] ## YEAR RACE MaxInc ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2010 African American 173200 ## 2 2010 Other 362000 ## 3 2010 White 637000 ## 4 2011 African American 376000 ## 5 2011 Other 200000 ## 6 2011 White 594000 ## 7 2012 African American 116000 ## 8 2012 Other 396000 ## 9 2012 White 461000 ## 10 2013 African American 398000 ## # ... with 20 more rows 5.6 join() We could use join() to do the same work of merge(). Name &lt;- c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;) # create variable Name MathScore &lt;- c(87, 98, 95) # create variable Score1 df1 &lt;- data.frame(Name, MathScore) # combine the variables into one data frame df1 ## Name MathScore ## 1 A 87 ## 2 B 98 ## 3 C 95 Name &lt;- c(&#39;B&#39;, &#39;D&#39;, &#39;C&#39;, &#39;A&#39;) # create variable Name PhysicsScore &lt;- c(99, 66, 98, 77) # create variable Score2 df2 &lt;- data.frame(Name, PhysicsScore) # combine the variables into one data frame df2 ## Name PhysicsScore ## 1 B 99 ## 2 D 66 ## 3 C 98 ## 4 A 77 df1 %&gt;% left_join(df2, by = &#39;Name&#39;) ## Name MathScore PhysicsScore ## 1 A 87 77 ## 2 B 98 99 ## 3 C 95 98 df1 %&gt;% right_join(df2, by = &#39;Name&#39;) ## Name MathScore PhysicsScore ## 1 A 87 77 ## 2 B 98 99 ## 3 C 95 98 ## 4 D NA 66 Could you tell the difference between left_join() and right_join()? Besides left_join() and right_join(), we have inner_join() (keep only matched observations of two data frames) and full_join() (keep all observations of two data frames). The codes below joins the poverty threshold dataset to the Minneapolis ACS dataset. ## import poverty threshold dataset poverty &lt;- read.csv(&#39;poverty.csv&#39;) head(poverty, 10) ## YEAR THRESHOLD ## 1 2010 11139 ## 2 2011 11484 ## 3 2012 11720 ## 4 2013 11888 ## 5 2014 12071 ## 6 2015 12082 ## 7 2016 12228 ## 8 2017 12488 ## 9 2018 12784 ## 10 2019 13011 The poverty threshold dataset lists the poverty threshold in terms of personal income in the US from 2010 to 2019. The data was retrieved from this link ## join the poverty threshold dataset to the Minneapolis ACS dataset based on YEAR minneapolis %&gt;% left_join(poverty, by = &#39;YEAR&#39;) %&gt;% head(10) ## YEAR SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC THRESHOLD ## 1 2010 2 59 1 0 10 1 33100 49100 11139 ## 2 2010 2 29 1 0 10 1 16000 49100 11139 ## 3 2010 1 54 2 0 7 3 1100 NA 11139 ## 4 2010 2 47 2 0 5 2 4800 4800 11139 ## 5 2010 1 59 2 0 10 2 0 4800 11139 ## 6 2010 2 10 2 0 1 0 NA 4800 11139 ## 7 2010 1 24 1 0 5 1 15000 15000 11139 ## 8 2010 1 26 2 3 6 1 18000 18000 11139 ## 9 2010 1 51 1 0 6 1 35200 74400 11139 ## 10 2010 2 47 1 0 6 1 39200 74400 11139 Sometimes, people from different groups may give the same variables with different variable names. In this case, you may need to change the codes a little bit. minneapolis %&gt;% rename(TIME = YEAR) %&gt;% ## rename the YEAR to TIME left_join(poverty, by = c(&#39;TIME&#39; = &#39;YEAR&#39;)) %&gt;% head(10) ## TIME SEX AGE RACE HISPAN EDUC EMPSTAT INCTOT FTOTINC THRESHOLD ## 1 2010 2 59 1 0 10 1 33100 49100 11139 ## 2 2010 2 29 1 0 10 1 16000 49100 11139 ## 3 2010 1 54 2 0 7 3 1100 NA 11139 ## 4 2010 2 47 2 0 5 2 4800 4800 11139 ## 5 2010 1 59 2 0 10 2 0 4800 11139 ## 6 2010 2 10 2 0 1 0 NA 4800 11139 ## 7 2010 1 24 1 0 5 1 15000 15000 11139 ## 8 2010 1 26 2 3 6 1 18000 18000 11139 ## 9 2010 1 51 1 0 6 1 35200 74400 11139 ## 10 2010 2 47 1 0 6 1 39200 74400 11139 rename() can help rename the column name in the data frame. 5.7 pivot_wider() and pivot_longer() in tidyr We can categorize the data frame into two types. One is long data, the other is wide data. In the long form, each row is a score of one discipline for one student. In the wide form, each row contains the scores of all three disciplines for one student. The long form and wide form data can be transformed to each other. We will use the example below as an illustration. max_income &lt;- minneapolis %&gt;% mutate( RACE = case_when( ## change RACE from numeric values to racial categories RACE == 1 ~ &#39;White&#39;, RACE == 2 ~ &#39;African American&#39;, RACE == 3 ~ &#39;Other&#39; ) ) %&gt;% group_by(YEAR, RACE) %&gt;% ## aggregate the data based on YEAR and RACE summarise(MaxInc = max(INCTOT, na.rm = T)) ## maximum personal income for different racial groups in each year head(max_income, 10) ## # A tibble: 10 x 3 ## # Groups: YEAR [4] ## YEAR RACE MaxInc ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2010 African American 173200 ## 2 2010 Other 362000 ## 3 2010 White 637000 ## 4 2011 African American 376000 ## 5 2011 Other 200000 ## 6 2011 White 594000 ## 7 2012 African American 116000 ## 8 2012 Other 396000 ## 9 2012 White 461000 ## 10 2013 African American 398000 We will use pivot_wider() and pivot_longer() in tidyr to do the task. ## import the package library(tidyr) ## from long to wide wide_data &lt;- max_income %&gt;% pivot_wider(names_from = RACE, values_from = MaxInc) wide_data ## # A tibble: 10 x 4 ## # Groups: YEAR [10] ## YEAR `African American` Other White ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2010 173200 362000 637000 ## 2 2011 376000 200000 594000 ## 3 2012 116000 396000 461000 ## 4 2013 398000 398000 867000 ## 5 2014 278000 459000 742000 ## 6 2015 477000 513000 557000 ## 7 2016 245000 469000 681000 ## 8 2017 120000 503000 731000 ## 9 2018 487000 337000 552000 ## 10 2019 193000 495000 831000 ## from wide to long wide_data %&gt;% pivot_longer(cols = `African American`:White, names_to = &#39;RACE&#39;, values_to = &#39;MaxInc&#39;) ## # A tibble: 30 x 3 ## # Groups: YEAR [10] ## YEAR RACE MaxInc ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2010 African American 173200 ## 2 2010 Other 362000 ## 3 2010 White 637000 ## 4 2011 African American 376000 ## 5 2011 Other 200000 ## 6 2011 White 594000 ## 7 2012 African American 116000 ## 8 2012 Other 396000 ## 9 2012 White 461000 ## 10 2013 African American 398000 ## # ... with 20 more rows "],["data-visualization-with-base-functions.html", "Chapter 6 Data Visualization with Base Functions 6.1 Scatter plot 6.2 Line plot 6.3 Bar plot 6.4 Add more elements in the plots 6.5 Pie chart 6.6 Boxplot 6.7 Color in R", " Chapter 6 Data Visualization with Base Functions We go through the base plotting functions in R in this chapter. ## import the Minneapolis ACS dataset minneapolis &lt;- read.csv(&#39;minneapolis.csv&#39;) 6.1 Scatter plot Scatter plot is a good way to show the distribution of data points. plot(minneapolis$AGE, minneapolis$INCTOT) # with first as x, and second as y Or, you could use the variable names directly and indicate the dataset as the codes below. You will get the same result. plot(INCTOT ~ AGE, data = minneapolis) # you have to specify the name of the data frame here 6.2 Line plot You could transfer the scatter plot above to a line plot by just adding a type variable to indicate that you are plotting a line. Line plot is good for presenting the trend of a variable changing by time. library(dplyr) mean_income &lt;- minneapolis %&gt;% group_by(YEAR) %&gt;% summarise(AvgInc = mean(INCTOT, na.rm = T)) plot(AvgInc ~ YEAR, data = mean_income, type = &#39;l&#39;) ## type indicates the line type with l You could also choose another type by changing the value of type, as the one below. plot(AvgInc ~ YEAR, data = mean_income, type = &#39;b&#39;) # b for both line and pint You could use help(plot) to check more styles of the plots. 6.3 Bar plot Bar plot is a good way to compare the values in each year or for each item. You could use barplot() to draw it. barplot(mean_income$AvgInc, names.arg = mean_income$YEAR) # names.org indicates the vector of names to be plotted under each bar 6.4 Add more elements in the plots For a reader-friendly plots, you have to add more information such as title, labels, and legend. For the plot above, we could use the codes below to make it more informative. barplot(mean_income$AvgInc, names.arg = mean_income$YEAR, main = &#39;Bar plot of the average personal income in Minneapolis (2010-2019)&#39;, # add title for the plot xlab = &#39;Year&#39;, # add label tag for the x-axis ylab = &#39;Personal income (dollars)&#39;, # add label for the y-axis ylim = c(0, 65000), # set the range of y axis, you could set the range of x axis with xlim legend = &#39;Personal income&#39;) # add legend name 6.5 Pie chart Pie chart is a good way to show the share of each part. You could use pie() function to draw a pie chart in R. minneaplis_race &lt;- minneapolis %&gt;% mutate( RACE = case_when( ## change RACE from numeric values to racial categories RACE == 1 ~ &#39;White&#39;, RACE == 2 ~ &#39;African American&#39;, RACE == 3 ~ &#39;Other&#39; ) ) %&gt;% group_by(RACE) %&gt;% summarise(count = n()) pie(minneaplis_race$count, # value for each piece labels = minneaplis_race$RACE) # label for each piece 6.6 Boxplot Box plot is also called box-whisker plot. It is to present the distribution of the dataset based on their quartiles. In R, you could use boxplot() to draw a box plot. t &lt;- c(1, 5, 10, 7, 8, 10, 11, 19) boxplot(t, range = 0) # set range = 0 makes the whiskers reach the smallest and largest values in the dataset t &lt;- c(1, 5, 10, 7, 8, 10, 11, 19) boxplot(t, range = 1) # set range = 1 makes the the whiskers extend to the most extreme data point which is no more than range times the interquartile range from the box 6.7 Color in R You could change the color of the plots by adding col = in the functions. For example. plot(AvgInc ~ YEAR, data = mean_income, type = &#39;b&#39;, col = &#39;YellowGreen&#39;) # specify the name of the color Here is a link where you could find the name of the color. You could also use the hexadecimal color code to indicate the color. For example. barplot(mean_income$AvgInc, names.arg = mean_income$YEAR, main = &#39;Bar plot of the average personal income in Minneapolis (2010-2019)&#39;, xlab = &#39;Year&#39;, ylab = &#39;Personal income (dollars)&#39;, ylim = c(0, 65000), legend = &#39;Personal income&#39;, col = &#39;#009999&#39;) # use the hexadecimal color code, you need to start it with the hash tag By the same link, you could also find the hexadcimal code for each color. "],["data-visualization-with-ggplot2.html", "Chapter 7 Data Visualization with ggplot2 7.1 Grammer of Graphics (gg) 7.2 Data, Aesthetics, and Geometries 7.3 Facets 7.4 Coordinates 7.5 Themes 7.6 Save plot", " Chapter 7 Data Visualization with ggplot2 In this chapter, we will learn using ggplot2 to carry out data visualization tasks. Before the lecture, please install the package first. install.packages(&#39;ggplot2&#39;) ## you only need to run this code once 7.1 Grammer of Graphics (gg) We have grammar for languages. Similarly, we have grammar for graphics. Thats where gg of ggplot2 comes from. ggplot2 has seven grammatical elements listed in the table below (DataCamp 2019). Element Description Data The dataset being plotted. Aesthetics The scales onto which we map our data. Geometries The visual elements used for our data. Facets Plotting small multiples (subplots). Statistics Representations of our data to aid understanding. Coordinates The space on which the data will be plotted. Themes All non-data ink. Lets take the codes below as an example to show how different elements work in ggplot2. Then, we might have an idea what is each element and how does it work. Firstly, we need to import the packages and the Minneapolis ACS dataset. We will use dplyr to wrangle the dataset. library(ggplot2) library(dplyr) minneapolis &lt;- read.csv(&#39;minneapolis.csv&#39;) ggplot(minneapolis, ## Data aes(x = AGE, y = INCTOT)) + ## Aesthetics geom_point() + ## Geometries facet_wrap(vars(YEAR)) + ## Facets stat_smooth(method = &quot;gam&quot;, se = FALSE, col = &quot;blue&quot;) + # Statistics scale_x_continuous(&#39;Age&#39;, limits = c(0, 100)) + scale_y_continuous(&#39;Personal income (dollars)&#39;) + # Coordinates labs(title = &#39;Age and personal income in Minneapolis (2010-2019)&#39;) + theme_bw() # Themes The figure shows the scatter plots of age and personal income in the city of Minneapolis from 2010 to 2019. In addition, the plot fits a nonlinear relationship (the blue line) between the age and personal income for each year. 7.2 Data, Aesthetics, and Geometries Generally, if you want to draw figures with ggplot2, you need at least three elements, which are data, aesthetics, and geometries. Data is the dataset we want to visualize. Aesthetic specifies how to map the variables to the scales in plots. Geometry indicates the plot type and related attributes. Take the example above again. We want to visualize the variables of AGE and TOTINC (aesthetic) of the dataset minneapolis (data, the Minneapolis ACS dataset) with a scatter plot (geometry). In summary, Similar to dplyr, ggplot2 also has its own fashion of coding. We start with the ggplot() function. Please pay attention that there is no 2 in the name of the function. In the function, we first indicate the name of the dataset (usually a data frame). Then we use aes() to indicate the scales we want to map our data. Here, we map AGE to x axis, and TOTINC to y axis. Then we use a plus sign + to connect it to other functions. We are going to draw a scatter plot, so we use geom_point(). We only use a 2017 subsample from the Minneapolis ACS dataset. Note that the observations with missing values have been removed during plotting (thats why we have a warning message). ## select a subsample of those in 2017 minneapolis_2017 &lt;- filter(minneapolis, YEAR == 2017) ## this example give us a simple example of ggplot2 ggplot(minneapolis_2017, # Data aes(x = AGE, y = INCTOT)) + # Aesthetics geom_point() # Geometries ## Warning: Removed 454 rows containing missing values (geom_point). Based on this plot, we have a overall idea of the relationship between AGE and TOTINC. When age increases, peoples personal income increases. However, after a certain age, peoples personal income decreases as their age increases. (This relationship is just a type of correlation, not causality.) In most cases, we will map variables to x axis and y axis. Therefore, we can replace the aes(x = AGE, y = INCTOT) to aes(AGE, INCTOT) to save some input (such as the codes below). We will stick to this style in the following lectures. Also, I recommend to put each function on a new line. ggplot(minneapolis_2017, aes(AGE, INCTOT)) + geom_point() We could add more scales as aesthetic elements in the plot. For example, we could use color to indicate the value of EDUC by adding col = EDUC. (col, color, and colour all work here.) ggplot(minneapolis_2017, aes(AGE, INCTOT, col = EDUC)) + geom_point() ## Warning: Removed 454 rows containing missing values (geom_point). Now we have more information in the result. While the respondent has a higher education level, s/he has a higher personal income. Here, EDUC is a continuous variable, so ggplot2 uses the darkness of color to indicate the value. If we use a categorical variable or a factor (e.g., binomial variable), ggplot2 will use different colors to show different levels. ## remove observations with missing employment status from the dataset ## change EMPSTAT from numeric values to corresponding characteristic values minneapolis_emp &lt;- minneapolis_2017 %&gt;% filter(EMPSTAT != 0) %&gt;% mutate( EMPSTAT = case_when( EMPSTAT == 1 ~ &#39;Employed&#39;, EMPSTAT == 2 ~ &#39;Unemployed&#39;, EMPSTAT == 3 ~ &#39;Not in labor force&#39; ) ) ggplot(minneapolis_emp, aes(AGE, INCTOT, col = EMPSTAT)) + geom_point() EMPSTAT stands for the employment status (employed, not in labor force, unemployed). R usually treats variables with characteristic values as factor. ggplot2 uses different colors to stand for different employment status. By reading the plot, we know that as age increases, more people are not in labor force. The personal income of employed people are higher than those not in labor force. (There are not many unemployed observations in this dataset, so it is hard to tell its pattern.) Besides color, there are several other scales can be used in plots. Continuous variable and categorical variable will generate different results when being mapped to these scales. Usually, color and shape work well with categorical variables. Size works well for continuous variables. But it still depends on the dataset you are dealing with. The best practice is always try it for yourself. Scales Description Continuous variable Categorical variable x x axis position  y y axis position  size Diameter of points, thickness of lines  alpha Transparency   color Color of dots, outlines of other shapes   fill Fill color   labels Text on a plot or axes  shape Shape of point  linetype Line dash pattern  If you want to set a scale to a fixed value, not a variable, you can do it in the geometry outside of aes(). ggplot(minneapolis_2017, aes(AGE, INCTOT)) + geom_point(col = &#39;blue&#39;) ## Warning: Removed 454 rows containing missing values (geom_point). ggplot(minneapolis_2017, aes(AGE, INCTOT)) + geom_point(alpha = 0.1) ## Warning: Removed 454 rows containing missing values (geom_point). Note that setting the value of alpha helps you recognize the density of the points in scatter plots. The plot above shows that the respondents are more distributed in the younger group. Geometry has many different types. For examples, geom_point() for scatter plot, geom_bar() for bar plot, geom_boxplot() for box plot, etc. Most functions of geometries are self-explained, so you could tell what their usages easily. We all talk about those commonly used geometries such as scatter plot, bar plot, line plot, etc in the following parts. 7.2.1 Scatter plot We use geom_point() to plot scatter plot. In the example below, we map AGE to x axis, and INCTOT to y axis. We indicate the color by set col = EDUC. The darkness of each point is decided by its value of EDUC (when the value is larger, the color is lighter). ggplot(minneapolis_2017, aes(AGE, INCTOT, col = EDUC)) + geom_point() ## Warning: Removed 454 rows containing missing values (geom_point). 7.2.2 Bar plot In the example below, we draw a bar plot to show the number of respondents in different racial groups. In aes(), we only indicate the variable RACE by setting x = RACE. R then will count the number of respondents for each racial groups. We, then, use geom_bar() to plot it. ggplot(minneapolis_2017, aes(x = RACE)) + geom_bar() In the following example, we count the number of respondents in each racial groups firstly. In the next step, we plot the bar plot by setting stat = 'identity' in geom_bar() to tell R to plot a bar plot based on the values directly (without counting). ## count the number of respondents based on RACE minneaplis_race &lt;- minneapolis_2017 %&gt;% group_by(RACE) %&gt;% summarise(count = n()) ggplot(minneaplis_race, aes(RACE, count)) + geom_bar(stat = &#39;identity&#39;) # you need to specify stat = &#39;identity&#39; to plot the value for each year Or you could use another geometry called geom_col() to do it. ggplot(minneaplis_race, aes(RACE, count)) + geom_col() ggplot(minneapolis_2017, aes(x = RACE, fill = factor(SEX))) + geom_bar() 7.2.3 Line plot In this example, we use geom_line() to draw a line plot. ## calculate the average personal income for each year minneapolis_year &lt;- minneapolis %&gt;% group_by(YEAR) %&gt;% summarise(AvgInc = mean(INCTOT, na.rm = T)) ## line plot of the trend of average personal income ggplot(minneapolis_year, aes(YEAR, AvgInc)) + geom_line(col = &#39;Blue&#39;) # indicate the color of the line by setting col = &#39;Blue&#39; If we map a variable to color in this plot, we will have several lines with different lines indicating different levels in the variable. ## calculate the average personal income for each racial group in each year minneapolis_year_race &lt;- minneapolis %&gt;% group_by(YEAR, RACE) %&gt;% summarise(AvgInc = mean(INCTOT, na.rm = T)) ## line plot of the trend of average personal income ggplot(minneapolis_year_race, aes(YEAR, AvgInc, col = factor(RACE))) + geom_line() 7.2.4 Boxplot In the example below, we draw a box plot for the personal income in each racial group. To do this, we map RACE to the x axis, and INCTOT to the y axis. We use factor() to transfer RACE to a factor (categorical variable). ggplot(minneapolis_2017, aes(factor(RACE), INCTOT)) + geom_boxplot() ## Warning: Removed 454 rows containing non-finite values (stat_boxplot). One problem of box plots is that they show the number of observations. For example, you do not have an idea how many points in each racial groups. We could use the geometry of jittering instead. Jittering randomly adds a little noise to the data points to avoid overlapping. The points in the plot below has been added some random noise in the direction of x axis. ggplot(minneapolis_2017, aes(factor(RACE), INCTOT)) + geom_jitter() ## Warning: Removed 454 rows containing missing values (geom_point). Another geometry is violin plot, which shows the density of the distribution. ggplot(minneapolis_2017, aes(factor(RACE), INCTOT)) + geom_violin() ## Warning: Removed 454 rows containing non-finite values (stat_ydensity). ggplot(minneapolis_2017, aes(factor(RACE), INCTOT, col = factor(SEX))) + geom_violin() ## Warning: Removed 454 rows containing non-finite values (stat_ydensity). 7.2.5 Pie chart In ggplot2, it is not as intuitive as the base function pie() to draw a pie chart. ggplot(minneaplis_race, aes(&#39;&#39;, count, fill = factor(RACE))) + geom_bar(width = 1, stat = &#39;identity&#39;) + coord_polar(&#39;y&#39;) # transfer the coordinate system to the polar one Whatggplot2 does here to draw a pie plot is to create a bar plot first. ggplot(minneaplis_race, aes(&#39;&#39;, count, fill = factor(RACE))) + geom_bar(width = 1, stat = &#39;identity&#39;) And then transfer the coordinate system to the polar one. ggplot(minneaplis_race, aes(&#39;&#39;, count, fill = factor(RACE))) + geom_bar(width = 1, stat = &#39;identity&#39;) + coord_polar(&#39;y&#39;) 7.3 Facets If you want to split up your data by one or more variables and plot each subset in one figure, facet is the element you want to use. In the following example, we draw a scatter plot for each racial group. In each plot, we map AGE to the x axis and INCTOT to y axis. The three plots are aligned in a row. p &lt;- ggplot(minneapolis_2017, aes(AGE, INCTOT)) +# store the plot result in variable p geom_point() p + facet_grid(. ~ RACE) # Facets, for each racial group ## Warning: Removed 454 rows containing missing values (geom_point). If we want to align the plots in a column, exchange the position of the variable in the function. p + facet_grid(RACE ~ .) # Facets, pay attention to the position of RACE and the dot sign ## Warning: Removed 454 rows containing missing values (geom_point). We could put more variables to split the plots. In the following example, we put one more variable SEX in the facet_grid(). p + facet_grid(SEX ~ RACE) # add vs ## Warning: Removed 454 rows containing missing values (geom_point). We could use the margins = T to add more plots showing the aggregation of the plots in each column or row. p + facet_grid(SEX ~ RACE, margins = T) # add aggregation plots for each row and column ## Warning: Removed 1816 rows containing missing values (geom_point). We could use labeller = label_both to add more information in the label. p + facet_grid(SEX ~ RACE, labeller = label_both) # add more info in the label ## Warning: Removed 454 rows containing missing values (geom_point). With facet_wrap(), we can spread the subplots evenly in the screen space. ggplot(minneapolis_2017, aes(AGE, INCTOT)) + geom_point() + facet_wrap(~EDUC) ## Warning: Removed 454 rows containing missing values (geom_point). Based on the plot, we have three observations. The first is the relationship between age and personal income. The second is that personal income grows as education level increases. The final one is that there are more respondents with higher education level in the survey than those with lower education level. 7.4 Coordinates While there are many coordinate systems supported by ggplot2, the most commonly used is Cartesian coordinate system, which is the combination of x axis and y axis orthogonally. 7.4.1 Zooming in and out In the following example, we zoom in our plot to a specific area. p &lt;- ggplot(minneapolis_2017, aes(AGE, INCTOT)) + geom_point() p + coord_cartesian(xlim = c(16, 100), ylim = c(0,20000)) ## Warning: Removed 454 rows containing missing values (geom_point). 7.4.2 Ratio We could change the ratio of the length of a y unit relative to the length of a x unit (\\(\\frac{\\text{y unit}}{\\text{x unit}}\\)). p &lt;- ggplot(minneapolis_2017, aes(AGE, EDUC)) + geom_point() p + coord_fixed(ratio = 1) ## 1 mean the units are same in x and y axis p + coord_fixed(ratio = 5) 7.4.3 Swaping the axes p + coord_flip() ggplot(minneapolis_2017, aes(factor(SEX), INCTOT)) + geom_boxplot() + coord_flip() ## Warning: Removed 454 rows containing non-finite values (stat_boxplot). ggplot(minneapolis_2017, aes(x = RACE)) + geom_bar() + scale_y_reverse() 7.4.4 Polar coordinate system We touched the polar coordinate system a little bit when drawing a pie chart. ggplot(minneapolis_2017, aes(x = &#39;&#39;, fill = factor(EDUC))) + geom_bar(width = 1) + coord_polar(theta = &#39;y&#39;) We could do this in a different way. ggplot(minneapolis_2017, aes(x = factor(EDUC))) + geom_bar(width = 1, col = &#39;Black&#39;, fill = &#39;Grey&#39;) + coord_polar() 7.5 Themes ggplot2 is powerful in its flexibility of themes. 7.5.1 Add labels Add labels with labs() function. p &lt;- ggplot(minneapolis_2017, aes(AGE, INCTOT)) + geom_point() + geom_smooth(method = &#39;loess&#39;) p + labs(title = &#39;Age and personal income in Minneapolis (2017)&#39;, # title of the plot subtitle = &#39;Data source: American Community Survey&#39;, # sub title x = &#39;Age&#39;, # x label y = &#39;Personal income (dollars)&#39;) # y label ## Warning: Removed 454 rows containing non-finite values (stat_smooth). ## Warning: Removed 454 rows containing missing values (geom_point). Or use ggtitle(), xlab(), and ylab() instead. p + ggtitle(&#39;Age and personal income in Minneapolis (2017)&#39;) + # title xlab(&#39;Age&#39;) + # x label ylab(&#39;Personal income (dollars)&#39;) # y label ## Warning: Removed 454 rows containing non-finite values (stat_smooth). ## Warning: Removed 454 rows containing missing values (geom_point). With value of NULL to remove labels. p + xlab(NULL) + # x label ylab(NULL) # y label ## Warning: Removed 454 rows containing non-finite values (stat_smooth). ## Warning: Removed 454 rows containing missing values (geom_point). 7.5.2 Change ticks Here is an example of changing the ticks for a discrete variable. p &lt;- ggplot(minneapolis_2017, aes(factor(SEX), INCTOT)) p + geom_boxplot() + scale_x_discrete(name = &quot;Gender&quot;, # name of the x axis labels = c(&#39;Male&#39;, &#39;Female&#39;)) # change 1 and 2 to Male and Female ## Warning: Removed 454 rows containing non-finite values (stat_boxplot). ggplot(minneapolis_year, aes(YEAR, AvgInc)) + geom_line(col = &#39;Blue&#39;) + scale_x_continuous(breaks = c(2010:2019)) + scale_y_continuous(breaks = seq(30000, 50000, 2500))## set the ticks 7.5.3 theme() function theme() function could change the styles of all components of plots. Here are a few examples about it (ggplot2 2019). p &lt;- ggplot(minneapolis_2017, aes(AGE, INCTOT)) + geom_point() + labs(title = &#39;Age and personal income in Minneapolis (2017)&#39;, subtitle = &#39;Data source: American Community Survey&#39;, x = &#39;Age&#39;, y = &#39;Personal income (dollars)&#39;) p # original plot ## Warning: Removed 454 rows containing missing values (geom_point). We could use plot.title to change the style of a title in the plot. In the following example, we change the font size of the title by setting element_text() and making size to be twice larger as the default one. p + theme(plot.title = element_text(size = rel(2))) ## Warning: Removed 454 rows containing missing values (geom_point). We could also use absolute value to indicate the size directly. p + theme(plot.title = element_text(size = 15)) ## Warning: Removed 454 rows containing missing values (geom_point). We could change the background of the plot by setting the value of plot.background in the theme() function. For example, if we want to change the color, we could set element_rect() and fill = 'red'. p + theme(plot.background = element_rect(fill = &#39;red&#39;)) ## Warning: Removed 454 rows containing missing values (geom_point). More specifically, if we want to change the style of the panel, which is the inner part restricted by x and y axes, we could set the value of panel.background. p + theme(panel.background = element_rect(fill = &#39;green&#39;, color = &#39;red&#39;)) ## Warning: Removed 454 rows containing missing values (geom_point). We could set the line type of the panels border. p + theme(panel.border = element_rect(linetype = &#39;dashed&#39;, fill = NA)) ## Warning: Removed 454 rows containing missing values (geom_point). Change the attributes of the lines for the grid. element_line() stands for the attributes of the lines. p + theme(panel.grid.major = element_line(colour = &#39;black&#39;), panel.grid.minor = element_line(colour = &#39;blue&#39;)) ## Warning: Removed 454 rows containing missing values (geom_point). Use element_blank() to remove the themes of the target. p + theme(panel.grid.major.y = element_blank(), panel.grid.minor.y = element_blank()) ## Warning: Removed 454 rows containing missing values (geom_point). We could put the grid line on the top of our data by setting panel.ontop = TRUE. p + theme( panel.background = element_rect(fill = NA), panel.grid.major = element_line(colour = &#39;Blue&#39;), panel.ontop = TRUE ) ## Warning: Removed 454 rows containing missing values (geom_point). Change the line style of the axis. p + theme( axis.line = element_line(size = 2, colour = &#39;red&#39;) ) ## Warning: Removed 454 rows containing missing values (geom_point). Change the text style of the axis. p + theme( axis.text = element_text(colour = &#39;Green&#39;, size = 15) ) ## Warning: Removed 454 rows containing missing values (geom_point). Change the attributes of the axis ticks. p + theme( axis.ticks = element_line(size = 1.5) ) ## Warning: Removed 454 rows containing missing values (geom_point). And y label. p + theme( axis.title.y = element_text(size = rel(1.5), angle = 30) ) ## Warning: Removed 454 rows containing missing values (geom_point). Now, lets see what we could do for the legend. p &lt;- ggplot(minneapolis_emp, aes(AGE, INCTOT, color = factor(EMPSTAT))) + geom_point() + labs( x = &#39;Age&#39;, y = &#39;Personal income (dollars)&#39;, color = &#39;Employment status&#39; ) p ## original plot Remove the legend by setting its position as legend.position = 'none'. p + theme( legend.position = &#39;none&#39; ) p + theme( legend.position = &#39;top&#39; ) By setting legend.justification for the legend, we anchor point for positioning legend inside plot (center or two-element numeric vector) or the justification according to the plot area when positioned outside the plot p + theme( legend.justification = &#39;top&#39; ) p + theme( legend.position = c(.95, .95), legend.justification = c(&#39;right&#39;, &#39;top&#39;), legend.box.just = &#39;right&#39; ) p + theme( legend.box.background = element_rect(), legend.box.margin = margin(6, 6, 6, 6) ) Set attributes for the key of the legend. p + theme( legend.key = element_rect(fill = &#39;white&#39;, colour = &#39;black&#39;) ) Set attributes for the text of the legend. p + theme( legend.text = element_text(size = 8, colour = &#39;red&#39;, face = &#39;bold&#39;) ) If you do not like to customize the theme one element by one element. ggplot2 also provides some function which give you a complete theme. For example, the theme_bw() we used at the start of this lecture. Note that complete theme can cover the setting of theme before it (not those after it). p + theme_bw() p + theme_minimal() p + theme_dark() Please check here for more complete theme. 7.6 Save plot You can use ggsave() to save the current plot. You need to specify the name (including file extension such as jpg, png) of the plot in the function. ggsave(&#39;plot.jpg&#39;, width = 5, height = 5) "],["statistics-in-r.html", "Chapter 8 Statistics in R 8.1 Plotting statistics 8.2 Anotation of statistics 8.3 Simple statistics 8.4 Linear regression 8.5 Logistic regression", " Chapter 8 Statistics in R In this chapter, we are going to use R to firstly drawing the statistics in the plots and carry out statistical analysis. library(dplyr) library(ggplot2) minneaplis &lt;- read.csv(&#39;minneapolis.csv&#39;) 8.1 Plotting statistics 8.1.1 Fitting the general trend of points You could fit a line to see the general trend of the scatter plot by adding stat_smooth(). ## select observations from 2017 minneapolis_2017 &lt;- filter(minneaplis, YEAR == 2017) p &lt;- ggplot(minneapolis_2017, aes(AGE, INCTOT)) + geom_point() p + stat_smooth(method = &#39;lm&#39;) # fit a linear line for the points ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 454 rows containing non-finite values (stat_smooth). ## Warning: Removed 454 rows containing missing values (geom_point). p + stat_smooth(method = &#39;loess&#39;) # non-linear line ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 454 rows containing non-finite values (stat_smooth). ## Warning: Removed 454 rows containing missing values (geom_point). It seems that the non-linear relationship makes more sense. 8.1.2 Plotting distribution You could draw a histogram for the dataset with geom_histogram(). p &lt;- ggplot(minneapolis_2017, aes(AGE)) p + geom_histogram(binwidth = 5) # the width of each category is 5 p + geom_histogram(bins = 30) # the number of bins is 30 You could fit a density line for the histogram. p + geom_histogram(aes( y = ..density..), binwidth = 5, col = &#39;Black&#39;, fill = &#39;White&#39;) + # use density instead of count geom_density(alpha = .2, fill = &#39;Grey&#39;) 8.1.3 Density plot of distribution geom_freqpoly() can serve a same purpose. p + geom_freqpoly() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 8.1.4 Box plot of distribution Another way to show more statistics about your data is box plot, which we have been introduced before. p &lt;- ggplot(minneapolis_2017, aes(factor(SEX), INCTOT)) p + geom_boxplot() ## Warning: Removed 454 rows containing non-finite values (stat_boxplot). 8.2 Anotation of statistics We can use geom_text() to annotate the statistics in the plot. 8.2.1 bar plot ggplot(minneapolis_2017, aes(x = RACE)) + geom_bar() + geom_text(aes(label = ..count..), stat = &quot;count&quot;, vjust = 1.5, colour = &quot;white&quot;) ## count the number of respondents based on RACE minneaplis_race &lt;- minneapolis_2017 %&gt;% group_by(RACE) %&gt;% summarise(count = n()) ggplot(minneaplis_race, aes(RACE, count)) + geom_col() + geom_text(aes(label = count), vjust = -0.3) 8.2.2 line plot ## calculate the average personal income for each year minneapolis_year &lt;- minneapolis %&gt;% group_by(YEAR) %&gt;% summarise(AvgInc = mean(INCTOT, na.rm = T)) ggplot(minneapolis_year, aes(YEAR, AvgInc)) + geom_line(col = &#39;Blue&#39;) + geom_text(aes(label = round(AvgInc)), vjust = -0.4) + scale_x_continuous(breaks = c(2010:2019)) ## calculate the average personal income for each racial group in each year minneapolis_year_race &lt;- minneapolis %&gt;% group_by(YEAR, RACE) %&gt;% summarise(AvgInc = mean(INCTOT, na.rm = T)) ## line plot of the trend of average personal income ggplot(minneapolis_year_race, aes(YEAR, AvgInc, col = factor(RACE))) + geom_line() + geom_text(aes(label = round(AvgInc)), vjust = -0.4, color = &#39;black&#39;) + scale_x_continuous(breaks = c(2010:2019)) 8.3 Simple statistics We have touched some of the functions in this topic. For example, we could use mean() to compute the average value of a set of numbers. 8.3.1 Mean and median We could use the base functions to do some simple statistical analysis directly. mean(minneapolis_2017$AGE) # mean ## [1] 36.0889 median(minneapolis_2017$AGE) # median ## [1] 32 8.3.2 Minimum and maximum value min(minneapolis_2017$AGE) # minimum value ## [1] 0 max(minneapolis_2017$AGE) # maximum value ## [1] 95 8.3.3 Quartile x &lt;- quantile(minneapolis_2017$AGE) x # list of quartiles ## 0% 25% 50% 75% 100% ## 0 20 32 52 95 x[2] # select the value by its index ## 25% ## 20 You could add value from 0 to 1 in the quantile() to find a specific value, for example, 40%. quantile(minneapolis_2017$AGE, 0.4) # 40% of the dataset ## 40% ## 28 8.4 Linear regression Before we start, lets review some related knowledge first. Regression is used to examine the linear relationships between the dependent variable and independent variables, where dependent variable is the one to be explained and independent variables (also called regressors, predictors, explanatory variables) are those may have influences on the dependent variable. For example, the dependent variable is personal income, and the independent variables are education, gender, age, etc. Among those independent variables, there are two types, one is continuous variable and the other is dummy variable. Continuous variable is variable with continuous values, such as income and age. Dummy variable is variable with values of 0 and 1. For example, gender, and people could use 1 for male, and 0 for female. Suppose we have a dependent variable \\(Y\\), and two independent variables \\(X_1\\) and \\(X_2\\), the regression model in assumption could be expressed as below, \\[Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\epsilon\\]. Where, \\(\\beta_0\\) is the intercept, \\(\\beta_1\\) and \\(\\beta_2\\) are coefficients for \\(X_1\\) and \\(X_2\\), \\(\\epsilon\\) is the error term which is the part of the dependent variable which cannot be explained by the intercept and independent variables. The target of regression is to estimate the value of \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\beta_2\\), and test their significance. The coefficients for the independent variables stand for that if the independent variable change one unit, the dependent variable will change the amount of the coefficients. The estimated model could be expressed as, \\[\\hat{Y} = \\hat{\\beta_0} + \\hat{\\beta_1}X_1 + \\hat{\\beta_2}X_2\\] Those variables with hat are estimated variables. While regression provides the estimated values of intercepts and coefficients, it also provides the significance of these estimates with p-values. When p-value is smaller, the estimates tend to be more significant. In R, the function will use some marks to indicate the significance levels. The significance level is the probability that the estimates are true. Mark Descriptions of significance level . 90% * 95% ** 99% *** 99.9% To quantify the fitness of the model, we use \\(R^2\\) with value from 0 to 1. When \\(R^2\\) is close to 1, the model fits the dataset well. \\(R^2\\) has a property that when adding more independent variables in the regression model, the \\(R^2\\) will increase. There is another index called adjusted \\(R^2\\), which considers the number of variables in the models. Our example is the Minneapolis ACS population dataset, and we want to explore the relationship between EDUC (Education level) and AGE (Age). Lets draw a scatter plot to see their distribution. ggplot(minneapolis_2017, aes(AGE, EDUC)) + geom_point() Because there are many overlapped points, we could add some noise to the positions of the points to help show all the points. ggplot(minneapolis_2017, aes(AGE, EDUC)) + geom_jitter(size = 0.5) ## add some noise to the positions of the points and set the size of the points to be 0.5 Based on the plot, it seems there is a positive relationship between these two variables. We add a linear line to fit them with geom_smooth(). ggplot(minneapolis_2017, aes(AGE, EDUC)) + geom_jitter(size = 0.5) + geom_smooth(method = &#39;lm&#39;) ## `geom_smooth()` using formula &#39;y ~ x&#39; To quantify this linear relationship, We could use lm() function to fit this linear relationship and use summary() function to see the result. In the function, the formula indicates the model in assumption. Here, our model in assumption is, \\[EDUC = \\beta_0 + \\beta_1 \\times AGE + \\epsilon\\] When we code this model in R, we do EDUC ~ AGE We only need to write down the variable names of the dependent variable and independent variables, and use ~ to connect them. No need to write the intercept and error term. We also need to indicate the name of the dataset in the function. lm_fit &lt;- lm(EDUC ~ AGE, # formula data = minneapolis_2017) # dataset summary(lm_fit) # check result ## ## Call: ## lm(formula = EDUC ~ AGE, data = minneapolis_2017) ## ## Residuals: ## Min 1Q Median 3Q Max ## -11.1979 -2.8243 0.3888 2.7364 5.1528 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.037407 0.114684 35.20 &lt;2e-16 *** ## AGE 0.078687 0.002741 28.71 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.102 on 2855 degrees of freedom ## Multiple R-squared: 0.224, Adjusted R-squared: 0.2237 ## F-statistic: 824.1 on 1 and 2855 DF, p-value: &lt; 2.2e-16 The summarized result provides details about the model results, such as the coefficients and p-values, the models \\(R^2\\), etc. Based on the information, we could know that the estimated coefficient for the intercept is 4.04, its p-value is \\(&lt; 2e-16\\) with a mark \\(***\\), showing it is significant at 99.9% level. The estimated coefficient for AGE is 0.08, its p-value is \\(&lt;2e-16\\) with a mark \\(***\\), showing it is significant at 99.9% level. We could also know the \\(R^2\\) is 0.224, and adjusted \\(R^2\\) is 0.2237. We could use the codes below to check the \\(R^2\\) of the model directly. summary(lm_fit)$r.squared # value of R2 ## [1] 0.2239978 And get the values of the coefficients directly. coefficients(lm_fit) # only check the coefficient ## (Intercept) AGE ## 4.03740708 0.07868725 The model can be improved. From the scatter plot between EDUC and AGE, many respondents get to their highest level of education before the age of 25. After 25, AGE has trivial influence on EDUC. We, then, are interested in the relationship before the age of 25. minneapolis_age &lt;- filter(minneapolis_2017, AGE &lt;= 25) ggplot(minneapolis_age, aes(AGE, EDUC)) + geom_jitter(size = 0.5) + geom_smooth(method = &#39;lm&#39;) ## `geom_smooth()` using formula &#39;y ~ x&#39; lm_fit &lt;- lm(EDUC ~ AGE, data = minneapolis_age) summary(lm_fit) ## ## Call: ## lm(formula = EDUC ~ AGE, data = minneapolis_age) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.3077 -1.0348 -0.0909 0.9091 3.9091 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.615627 0.087077 -18.55 &lt;2e-16 *** ## AGE 0.405604 0.005307 76.43 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.303 on 1006 degrees of freedom ## Multiple R-squared: 0.8531, Adjusted R-squared: 0.8529 ## F-statistic: 5841 on 1 and 1006 DF, p-value: &lt; 2.2e-16 The model provides better fitness to the dataset now. Most of the time, we need to examine the relationship between the dependent variable and more than one independent variable. In this case, drawing a plot to check the relationship before the analysis is not a good idea. We just do the regression directly. The example below examines the relationship between EDUC and AGE, SEX, and RACE. when there is more than one independent variables, we use + to connect them in the formula. RACE is a categorical variable, so we transform it to a factor. mlm_fit &lt;- lm(EDUC ~ AGE + SEX + factor(RACE), minneapolis_2017) summary(mlm_fit) ## ## Call: ## lm(formula = EDUC ~ AGE + SEX + factor(RACE), data = minneapolis_2017) ## ## Residuals: ## Min 1Q Median 3Q Max ## -10.4126 -2.2219 0.4191 2.4941 6.5838 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.020836 0.208105 24.126 &lt;2e-16 *** ## AGE 0.070253 0.002684 26.170 &lt;2e-16 *** ## SEX -0.044017 0.110679 -0.398 0.691 ## factor(RACE)2 -2.413424 0.160769 -15.012 &lt;2e-16 *** ## factor(RACE)3 -1.714259 0.159498 -10.748 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.957 on 2852 degrees of freedom ## Multiple R-squared: 0.2955, Adjusted R-squared: 0.2945 ## F-statistic: 299.1 on 4 and 2852 DF, p-value: &lt; 2.2e-16 summary(mlm_fit)$r.squared ## [1] 0.2955301 Again, without careful research design, the relationships shown by the regression model are all correlations, not causalities. 8.5 Logistic regression The above two examples both use continuous variables as their dependent variables. How about using a binomial variable (0 or 1 as its value) a dependent variable? Then we need to do logistic regression. There are many functions to do this. When interpreting the coefficients of the logistic regression result, the coefficient stands for the change of the log odds of the dependent variable to 1. Here, we introduce the glm() function. We need to indicate family = binomial in the function. ## create a variable to indicate the poverty status of the respondents minneapolis_poverty &lt;- minneapolis_2017 %&gt;% filter(!is.na(INCTOT)) %&gt;% mutate(poverty = ifelse(INCTOT &lt;= 12228, 1, 0)) ## logistic regression logit_reg &lt;- glm(poverty ~ AGE + EDUC + SEX + factor(RACE), minneapolis_poverty, family = binomial) summary(logit_reg) ## ## Call: ## glm(formula = poverty ~ AGE + EDUC + SEX + factor(RACE), family = binomial, ## data = minneapolis_poverty) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.3815 -0.7066 -0.5090 0.8830 2.8188 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 3.018926 0.270700 11.152 &lt; 2e-16 *** ## AGE -0.031852 0.002971 -10.720 &lt; 2e-16 *** ## EDUC -0.367547 0.022532 -16.312 &lt; 2e-16 *** ## SEX 0.096235 0.101052 0.952 0.341 ## factor(RACE)2 0.646833 0.145549 4.444 8.83e-06 *** ## factor(RACE)3 0.168694 0.146323 1.153 0.249 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2983.5 on 2402 degrees of freedom ## Residual deviance: 2391.9 on 2397 degrees of freedom ## AIC: 2403.9 ## ## Number of Fisher Scoring iterations: 4 Most of the information is similar with regression ones except that the logistic regression does not have \\(R^2\\) and adjusted \\(R^2\\). It uses AIC (Akaike information criterion) in indicate the goodness of the model. If one model has smaller AIC, it is better. "],["exploratory-data-analysis.html", "Chapter 9 Exploratory Data Analysis 9.1 Case 1: Race and personal income in the city of Minneapolis (2010-2019) 9.2 Case 2: Race and employment rate in the city of Minneapolis (2010-2019) 9.3 Case 3: Population density and election result in the US (2020)", " Chapter 9 Exploratory Data Analysis We are going to use what we have learned so far to do exploratory data analysis. It is also a practice for data manipulation and visualization. Instead of importing dplyr and ggplot2, we import tidyverse this time. tidyverse includes both dplyr and ggplot2. Besides, it also has some other useful packages, such as tidyr (data manipulation) and stringr (deal with characteristics and string data). library(tidyverse) ## -- Attaching packages --------------------------------------- tidyverse 1.3.0 -- ## v tibble 3.0.5 v stringr 1.4.0 ## v readr 1.4.0 v forcats 0.5.0 ## v purrr 0.3.4 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() 9.1 Case 1: Race and personal income in the city of Minneapolis (2010-2019) The data we have is the Minneapolis ACS dataset. You need to download the DDI file (xml file) and the dataset (DAT file) before dealing with the data. Then you can use the code below to import the dataset. ## import the ipumsr package library(ipumsr) ## import dataset ddi &lt;- read_ipums_ddi(&#39;usa_00003.xml&#39;) ## you may need to change the file name data &lt;- read_ipums_micro(ddi) After importing the dataset, usually you have to do some pre-processing before exploring the data. Below are some examples: 1. Remove the labels. The IPUMS dataset has labels. In this lecture, you may want to remove them. 2. Select some observations for further analysis. 3. Reduce the levels of some categorical variables. RACE originally has 9 levels. Here, we only keep the codes for White and African American and aggregate other races to one level. 4. Change the missing value to NA. Some survey data use codes such as 9999, 999998 to stand for missing values. We may need to change those to NA. 5. Select the variables for further analysis. minneapolis &lt;- data %&gt;% zap_labels() %&gt;% ## remove labels from the data filter(CITY == 4150) %&gt;% ## select the city of Minneapolis (city code is 4150) mutate(RACE = ifelse(RACE &gt;= 3, 3, RACE), ## select three racial groups INCTOT = ifelse(INCTOT == 9999999, NA, INCTOT), ## change missing value to NA FTOTINC = ifelse(FTOTINC %in% c(9999999, 999998), NA, FTOTINC)) %&gt;% select(YEAR, SEX, AGE, RACE, HISPAN, EDUC, EMPSTAT, INCTOT, FTOTINC) ## select variables I skip the variable introduction as we have been very familiar with them. You may find the variable introduction by this link. The codes below calculate the personal income for each racial group from 2010 to 2019. minneapolis_race &lt;- minneapolis %&gt;% group_by(YEAR, RACE) %&gt;% ## calculate average personal income for races and years summarise(AvgInc = mean(INCTOT, na.rm = T)) %&gt;% mutate(RACE = case_when( ## change race from numbers to their corresponding labels RACE == 1 ~ &#39;White&#39;, RACE == 2 ~ &#39;African American&#39;, RACE == 3 ~ &#39;Other&#39; )) head(minneapolis_race, 10) ## # A tibble: 10 x 3 ## # Groups: YEAR [4] ## YEAR RACE AvgInc ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2010 White 42938. ## 2 2010 African American 18596. ## 3 2010 Other 21891. ## 4 2011 White 42889. ## 5 2011 African American 19054. ## 6 2011 Other 19940. ## 7 2012 White 38157. ## 8 2012 African American 17045. ## 9 2012 Other 22724. ## 10 2013 White 43206. The codes below draw a line plot to show the results. ggplot(minneapolis_race, aes(YEAR, AvgInc, color = RACE)) + ## line plot geom_line() + geom_point() We may need to make it more readable to the audience by adding more elements and change the font size of some texts. ggplot(minneapolis_race, aes(YEAR, AvgInc, color = RACE)) + ## line plot geom_line() + geom_point() + labs(x = &#39;Year&#39;, y = &#39;Average personal income (Dollars)&#39;, color = &#39;RACE&#39;, title = &#39;Race and personal income in Minneaplis (2010-2019)&#39;) + scale_x_continuous(breaks = c(2010:2019)) + ## adjust x axis tick labels theme_bw() + theme(legend.position = &#39;bottom&#39;, ## adjust legend position axis.text = element_text(size = 10), ## adjust font sizes for different components axis.title = element_text(size = 12), plot.title = element_text(size = 14), legend.text = element_text(size = 10), legend.title = element_text(size = 10)) Finally, we can combine the data manipulation and visualization codes together. ## line plot of the relationships between race and income minneapolis %&gt;% group_by(YEAR, RACE) %&gt;% ## calculate average personal income for races and years summarise(AvgInc = mean(INCTOT, na.rm = T)) %&gt;% mutate(RACE = case_when( ## change race from numbers to their corresponding labels RACE == 1 ~ &#39;White&#39;, RACE == 2 ~ &#39;African American&#39;, RACE == 3 ~ &#39;Other&#39; )) %&gt;% ggplot(aes(YEAR, AvgInc, color = RACE)) + ## line plot geom_line() + geom_point() + labs(x = &#39;Year&#39;, y = &#39;Average personal income (Dollars)&#39;, color = &#39;RACE&#39;, title = &#39;Race and personal income in Minneaplis (2010-2019)&#39;) + scale_x_continuous(breaks = c(2010:2019)) + ## adjust x axis tick labels theme_bw() + theme(legend.position = &#39;bottom&#39;, ## adjust legend position axis.text = element_text(size = 10), ## adjust font sizes for different components axis.title = element_text(size = 12), plot.title = element_text(size = 14), legend.text = element_text(size = 10), legend.title = element_text(size = 10)) From this plot, we see that the personal income of minority groups are much lower than that of the White. In addition, the personal income of the African Americans are relatively stable during the study time period and has increased very little. You may want to save the plot. ggsave(&#39;race_income.jpg&#39;, width = 8, height = 6, dpi = 600) ## save the plot 9.2 Case 2: Race and employment rate in the city of Minneapolis (2010-2019) In the second case, we see how programming in R help increase work efficiency. The problem in case 2 is quite similar to that in the first case. Therefore, we only need to change the codes in case 1 a little bit and then we can have the result. ## line plot of the relationship between race and employment status minneapolis %&gt;% group_by(YEAR, RACE, EMPSTAT) %&gt;% ## calculate average employment rate for races and years summarise(count = n()) %&gt;% filter(EMPSTAT != 0, EMPSTAT != 3) %&gt;% group_by(YEAR, RACE) %&gt;% mutate(per = count/sum(count)*100) %&gt;% filter(EMPSTAT == 1) %&gt;% mutate(RACE = case_when( ## change race from numbers to their corresponding labels RACE == 1 ~ &#39;White&#39;, RACE == 2 ~ &#39;African American&#39;, RACE == 3 ~ &#39;Other&#39; )) %&gt;% ggplot(aes(YEAR, per, color = factor(RACE))) + ## line plot geom_line() + geom_point() + labs(x = &#39;Year&#39;, y = &#39;Average employment rate (%)&#39;, color = &#39;RACE&#39;, title = &#39;Race and employment rate in Minneaplis (2010-2019)&#39;) + scale_x_continuous(breaks = c(2010:2019)) + scale_y_continuous(limits = c(70, 100), breaks = c(75, 80, 85, 90, 95, 100)) + theme_bw() + theme(legend.position = &#39;bottom&#39;, ## adjust legend position axis.text = element_text(size = 10), ## adjust font sizes for different components axis.title = element_text(size = 12), plot.title = element_text(size = 14), legend.text = element_text(size = 10), legend.title = element_text(size = 10)) We see that the employment rate of the minority groups have been improved a lot during the study period, especially for African Americans. However, the minority groups have relatively lower employment rate than the White. 9.3 Case 3: Population density and election result in the US (2020) We first import the dataset we need. Population density at the county level is retrieved from the US Census Bureau (link). Election results at the county level is retrieved from a GitHub repo (link). pop_density &lt;- read_csv(&#39;pop_density.csv&#39;) election &lt;- read_csv(&#39;2020_election.csv&#39;) We, then, Join the population density dataset to the election result dataset. The variable used to join two datasets is the ID of each county. In the population density dataset, it is GEOID. In the election result dataset, it is county_fips. Select two variables from the dataset. per_point_diff is the difference between the vote share for Trump and that for Biden. Select observations without missing values. Rename the two variables. election %&gt;% left_join(pop_density, by = c(&#39;county_fips&#39;=&#39;GEOID&#39;)) %&gt;% ## join two datasets select(per_point_diff, B01001_calc_PopDensity) %&gt;% ## select two variables filter(complete.cases(.)) %&gt;% ## select observations without missing values rename(diff = per_point_diff, ## rename the variables popden = B01001_calc_PopDensity) %&gt;% head() ## # A tibble: 6 x 2 ## diff popden ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.444 35.9 ## 2 0.538 50.5 ## 3 0.0766 11.2 ## 4 0.577 14.0 ## 5 0.800 34.5 ## 6 -0.499 6.42 We draw a simple scatter plot to see the distribution of the two variables. It seems that the x axis need some transformation based on the distribution. Note that we map -diff to the x axis instead of mapping diff directly. election %&gt;% left_join(pop_density, by = c(&#39;county_fips&#39;=&#39;GEOID&#39;)) %&gt;% select(per_point_diff, B01001_calc_PopDensity) %&gt;% filter(complete.cases(.)) %&gt;% rename(diff = per_point_diff, popden = B01001_calc_PopDensity) %&gt;% ggplot(aes(popden, -diff)) + ## simple scatter plot geom_point() We transform the x axis with logarithm through scale_x_log10(). The plot looks much better. election %&gt;% left_join(pop_density, by = c(&#39;county_fips&#39;=&#39;GEOID&#39;)) %&gt;% select(per_point_diff, B01001_calc_PopDensity) %&gt;% filter(complete.cases(.)) %&gt;% rename(diff = per_point_diff, popden = B01001_calc_PopDensity) %&gt;% ggplot(aes(popden, -diff)) + geom_point() + scale_x_log10() ## transform the x axis with logarithm Below are some steps to further improve the plot. Map popden to the size of the points. Create a variable party. When its value is 0, it means Trump won that county. When its value is 1, it means Biden won that county. Map this variable to the color of the points. Use scale_fill_manual() to set the color for each value of party: red for 0 and blue for 1. Set the shape of the point to 21 and set the border color as white. Set the ticks of the x axis and y axis to specific values. Set the range of y axis. Add a horizontal line at 0 with geom_hline(). Change the labels of x axis, y axis, and title. Add the complete theme theme_bw(). Remove the legend. Set the font size for axis labels and title. election %&gt;% left_join(pop_density, by = c(&#39;county_fips&#39;=&#39;GEOID&#39;)) %&gt;% select(per_point_diff, B01001_calc_PopDensity) %&gt;% filter(complete.cases(.)) %&gt;% rename(diff = per_point_diff, popden = B01001_calc_PopDensity) %&gt;% mutate(party = ifelse(diff &gt; 0, 0, 1)) %&gt;% ## create a variable ggplot(aes(popden, -diff, size = popden, fill = factor(party))) + ## map population density to size and party to fill of the points geom_point(shape = 21, color = &#39;white&#39;) + ## change the shape of the point and set the border color to white scale_fill_manual(values = c(&#39;red&#39;, &#39;blue&#39;)) + ## set the color for party scale_x_log10(breaks = c(0.1, 1, 10, 100, 1000, 10000), ## set the ticks for x axis labels = c(&#39;0.1&#39;, &#39;1&#39;, &#39;10&#39;, &#39;100&#39;, &#39;1000&#39;, &#39;10000&#39;)) + scale_y_continuous(limits = c(-1, 1), ## set the color for y axis breaks = c(-1, -0.5, 0, 0.5, 1), labels= c(&#39;-100&#39;, &#39;-50&#39;, &#39;0&#39;, &#39;50&#39;, &#39;100&#39;)) + geom_hline(yintercept = 0) + ## add a horizontal line at 0 labs(title = &#39;Election result and population density in US (2020)&#39;, ## change labels x = &#39;Population density (people/sq km)&#39;, y = &#39;Vote margin (%)&#39;) + theme_bw() + theme(legend.position = &#39;none&#39;, ## remove legend axis.text = element_text(size = 10), ## adjust font size for different components axis.title = element_text(size = 12), plot.title = element_text(size = 14)) What can you learn from this plot about the relationship between election result and population density? "],["final-project.html", "Chapter 10 Final Project 10.1 Description 10.2 Timeline 10.3 Proposal of problem statement 10.4 Potential data sources 10.5 Final submission", " Chapter 10 Final Project 10.1 Description R is the tool serving for analyzing data and visualizing results. In the final project, you will use the R programming skills you learn from this course and also the knowledge outside the course (other R techniques you are interested in and your professional knowledge in your study major) to solve a research question. The research question could be related your study field (e.g., public policy, urban and regional planning, public health, etc.), or what you are interested in, or your previous course or research project but you do it with R instead. The originality of your research question is not necessary. You could use any packages in R to solve the problem. For example, you could use plots to do descriptive analysis. Or you could use regression to find correlation or causality. The final product is a poster. This assignment accounts for 30% of your final grades. 10.2 Timeline To accomplish the final project, you need to finish two tasks. Task Descriptions Due Date 1 Proposal Your research question and data source introduction 16th Apr. 2 Poster A poster representing your analysis result 7th May. 10.3 Proposal of problem statement In this task, you will need to submit the proposal file (either word or pdf). The instructor will give you feedback but will not grade this part. The rubric is just for helping you check the requirements. See the canvas for a template of the proposal. Requirements Research question and illustration of research question is clear Clearly state the data sources (what is the dataset and where do you find it) State the potential method you will use for data analysis (descriptive analysis, simple regression, etc.) The proposal should be less than one page, 12 font size. 10.4 Potential data sources IMPUS USA National Household Travel Survey Minnesota Geospatial Commons Open Minneapolis 10.5 Final submission In this part, you will submit your data file, revised codes (R file), and the poster (PDF file). The instructor will grade them based on the rubric below. The poster should include research question (as the title of the poster), your name, illustration of your research question, data source, plots/tables, and important findings should include at least two plots generated by your R codes should include no more than four plots could include include one table generated by your R codes, but not necessarily Category Requirements Grades Codes Codes could generate the results (figures, tables, and related statistics) 7 Necessary notes for the codes 2 Codes is neat and well-organized 1 Poster Research question and study purpose are clear 2 Clearly state the data sources (what is the dataset, where do you find it, what variables you use from this dataset) 2 Figures contain the necessary parts, well-organized, and visually good/ tables are well-organized 12 Description of the important findings is clear 2 Poster is well-organized 2 You can find a poster template file (PowerPoint file) on Canvas website. You can choose to follow the format of this template or change it. "],["references.html", "Chapter 11 References", " Chapter 11 References BiomedicalDataScience. 2019. Dplyr Tutorial. October 23, 2019. https://genomicsclass.github.io/book/pages/dplyr_tutorial.html. Blischak, John, Daniel Chen, Harriet Dashnow, and Denis Haine. 2019. Data Types and Structures. October 8, 2019. https://swcarpentry.github.io/r-novice-inflammation/13-supp-data-structures/. DataCamp. 2019. Data Visualization with Ggplot2. November 3, 2019. https://www.datacamp.com/courses/data-visualization-with-ggplot2-1. DataMentor. 2019. R Operators. October 11, 2019. https://www.datamentor.io/r-programming/operator/. ggplot2. 2019. Modify Components of a Theme. November 5, 2019. https://ggplot2.tidyverse.org/reference/theme.html. Kabacoff, Robert I. 2019. Data Types. October 8, 2019. https://www.statmethods.net/input/datatypes.html. Quick-R. 2019a. Exporting Data. October 21, 2019. https://www.statmethods.net/input/exportingdata.html. . 2019b. Getting Information on a Dataset. October 21, 2019. https://www.statmethods.net/input/contents.html. . 2019c. Importing Data. October 21, 2019. https://www.statmethods.net/input/importingdata.html. r-project. 2019. Introduction to Dplyr. October 23, 2019. https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html. Selvam, Sindhu. 2019. Introduction to RStudio. October 8, 2019. https://datascienceplus.com/introduction-to-rstudio/. tutorialspoint. 2019a. R - Operators. October 8, 2019. https://www.tutorialspoint.com/r/r_operators.htm. . 2019b. R - Variables. October 13, 2019. https://www.tutorialspoint.com/r/r_variables.htm. "]]
